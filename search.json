[{"path":"https://pkg.robjhyndman.com/weird-package/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rob Hyndman. Author, maintainer, copyright holder. RStudio. Copyright holder.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hyndman RJ (2024). weird: Functions Data Sets \"Weird: Anomaly Detection Using R\" Rob J Hyndman. R package version 1.0.2.9000, https://pkg.robjhyndman.com/weird-package/. Hyndman RJ (2024). Weird: Anomaly Detection Using R. OTexts, Melbourne, Australia. preparation, https://OTexts.com/weird/.","code":"@Manual{,   title = {{weird: Functions and Data Sets for \"That's Weird: Anomaly Detection Using R\" by Rob J Hyndman}},   author = {Rob J Hyndman},   year = {2024},   note = {R package version 1.0.2.9000},   url = {https://pkg.robjhyndman.com/weird-package/}, } @Book{,   title = {That's Weird: Anomaly Detection Using {R}},   author = {Rob J Hyndman},   year = {2024},   note = {In preparation},   publisher = {OTexts},   address = {Melbourne, Australia},   url = {https://OTexts.com/weird/}, }"},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Functions and Data Sets for ","text":"weird package contains functions data used book ’s Weird: Anomaly Detection Using R Rob J Hyndman. also loads several packages needed analysis described book.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Functions and Data Sets for ","text":"can install stable version CRAN : can install development version weird GitHub :","code":"install.packages(\"weird\") # install.packages(\"devtools\") devtools::install_github(\"robjhyndman/weird-package\")"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Functions and Data Sets for ","text":"library(weird) load following packages: dplyr, data manipulation. ggplot2, data visualisation. distributional, handling probability distributions. also get condensed summary conflicts packages loaded:","code":"library(weird) #> ── Attaching packages ────────────────────────────────────────────────────────── weird 1.0.2.9000 ── #> ✔ dplyr          1.1.4     ✔ distributional 0.5.0 #> ✔ ggplot2        3.5.1 #> ── Conflicts ──────────────────────────────────────────────────────────────────── weird_conflicts ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag()"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"example-old-faithful-geyser-data","dir":"","previous_headings":"","what":"Example: Old Faithful Geyser data","title":"Functions and Data Sets for ","text":"oldfaithful data set contains eruption data Old Faithful Geyser Yellowstone National Park, Wyoming, USA, 1 January 2015 1 October 2021. data obtained geysertimes.org website. Recordings incomplete, especially winter months observers may present. also appear recording errors. data set contains 2261 observations 3 variables: time giving time eruption began, duration giving length eruption seconds, waiting giving time next eruption seconds. analysis , omit eruption duration greater 1 hour likely recording error. long waiting values probably due omitted eruptions, also omit eruptions waiting greater 2 hours.","code":"oldfaithful #> # A tibble: 2,261 × 3 #>    time                duration waiting #>    <dttm>                 <dbl>   <dbl> #>  1 2015-01-02 14:53:00      271    5040 #>  2 2015-01-09 23:55:00      247    6060 #>  3 2015-02-07 00:49:00      203    5460 #>  4 2015-02-14 01:09:00      195    5221 #>  5 2015-02-21 01:12:00      210    5401 #>  6 2015-02-28 01:11:00      185    5520 #>  7 2015-03-07 00:50:00      160    5281 #>  8 2015-03-13 21:57:00      226    6000 #>  9 2015-03-13 23:37:00      190    5341 #> 10 2015-03-20 22:26:00      102    3961 #> # ℹ 2,251 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"kernel-density-estimates","dir":"","previous_headings":"","what":"Kernel density estimates","title":"Functions and Data Sets for ","text":"package provides kde_bandwidth() function estimating bandwidth kernel density estimate, dist_kde() constructing distribution, gg_density() plotting resulting density. figure shows kernel density estimate duration variable obtained using functions.  functions also work bivariate data. figure shows kernel density estimate duration waiting variables.","code":"of <- oldfaithful |>   filter(duration < 3600, waiting < 7200) dist_kde(of$duration) |>   gg_density(show_points = TRUE, jitter = TRUE) +   labs(x = \"Duration (seconds)\") of |>   select(duration, waiting) |>   dist_kde() |>   gg_density(show_points = TRUE, alpha = 0.15) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\")"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"statistical-tests","dir":"","previous_headings":"","what":"Statistical tests","title":"Functions and Data Sets for ","text":"old methods anomaly detection used statistical tests. recommended, still widely used, provided package comparison purposes. example, detect tiny 1-second duration, almost certainly recording error. explanation tests provided Chapter 4 book","code":"of |> filter(peirce_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700 of |> filter(chauvenet_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700 of |> filter(grubbs_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700 of |> filter(dixon_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"boxplots","dir":"","previous_headings":"","what":"Boxplots","title":"Functions and Data Sets for ","text":"Boxplots widely used anomaly detection. three variations boxplots applied duration variable.    latter two plots highest density region (HDR) boxplots, allow bimodality data seen. dark shaded region contains 50% observations, lighter shaded region contains 99% observations. plots use vertical jittering reduce overplotting, highlight potential outliers (points lying outside 99% HDR). explanation plots provided Chapter 5 book. also possible produce bivariate boxplots. Several variations provided package. two types bagplot.   two types HDR boxplot   latter two plots show possible outliers black (, defined points outside 99% HDR).","code":"of |>   ggplot(aes(x = duration)) +   geom_boxplot() +   scale_y_discrete() +   labs(y = \"\", x = \"Duration (seconds)\") of |> gg_hdrboxplot(duration) +   labs(x = \"Duration (seconds)\") of |> gg_hdrboxplot(duration, show_points = TRUE) +   labs(x = \"Duration (seconds)\") of |>   gg_bagplot(duration, waiting) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\") of |>   gg_bagplot(duration, waiting, scatterplot = TRUE) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\") of |>   gg_hdrboxplot(duration, waiting) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\") of |>   gg_hdrboxplot(duration, waiting, scatterplot = TRUE) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\")"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"scoring-functions","dir":"","previous_headings":"","what":"Scoring functions","title":"Functions and Data Sets for ","text":"Several functions provided providing anomaly scores observations. surprisals() function uses either fitted statistical model, kernel density estimate, compute density scores. stray_scores() function uses stray algorithm compute anomaly scores. lof_scores() function uses local outlier factors compute anomaly scores. glosh_scores() function uses Global-Local Outlier Score Hierarchies algorithm compute anomaly scores. lookout_prob() function uses lookout algorithm Kandanaarachchi & Hyndman (2022) compute anomaly probabilities. top 0.02% anomalous observations identified methods. surprisals() function can also compute probability obtaining surprisal values least extreme observed. fact, default behaviour, obtained probability = TRUE.","code":"of |>   mutate(     surprisal = surprisals(cbind(duration, waiting), probability = FALSE),     strayscore = stray_scores(cbind(duration, waiting)),     lofscore = lof_scores(cbind(duration, waiting), k = 150),     gloshscore = glosh_scores(cbind(duration, waiting)),     lookout = lookout_prob(cbind(duration, waiting))   ) |>   filter(     surprisal > quantile(surprisal, prob = 0.998) |       strayscore > quantile(strayscore, prob = 0.998) |       lofscore > quantile(lofscore, prob = 0.998) |       gloshscore > quantile(gloshscore, prob = 0.998) |       lookout < 0.002   ) |>   arrange(lookout) #> # A tibble: 10 × 8 #>    time                duration waiting surprisal strayscore lofscore gloshscore  lookout #>    <dttm>                 <dbl>   <dbl>     <dbl>      <dbl>    <dbl>      <dbl>    <dbl> #>  1 2018-04-25 19:08:00        1    5700      17.9     0.380      3.78      1     0        #>  2 2020-06-01 21:04:00      120    6060      17.8     0.132      1.88      1     3.99e-10 #>  3 2021-01-22 18:35:00      170    3600      16.9     0.0606     1.09      0.860 4.83e- 5 #>  4 2020-08-31 09:56:00      170    3840      16.7     0.0606     1.01      0.816 4.11e- 4 #>  5 2015-11-21 20:27:00      150    3420      16.2     0.0772     1.27      1     4.10e- 3 #>  6 2020-10-15 17:11:00      220    7080      15.7     0.0429     2.42      1     3.46e- 2 #>  7 2017-08-12 13:14:00      120    4920      15.0     0.0690     1.53      1     1.42e- 1 #>  8 2017-09-22 18:51:00      281    7140      15.0     0.0333     2.64      1     1.81e- 1 #>  9 2020-05-18 21:21:00      272    7080      14.5     0.0333     2.42      1     4.02e- 1 #> 10 2018-09-22 16:37:00      253    7140      14.6     0.0200     2.63      1     4.05e- 1 of |>   mutate(     surprisal = surprisals(cbind(duration, waiting), probability = FALSE),     prob = surprisals(cbind(duration, waiting))   ) |>   arrange(prob) #> # A tibble: 2,197 × 5 #>    time                duration waiting surprisal     prob #>    <dttm>                 <dbl>   <dbl>     <dbl>    <dbl> #>  1 2018-04-25 19:08:00        1    5700      17.9 0.000455 #>  2 2020-06-01 21:04:00      120    6060      17.8 0.000910 #>  3 2021-01-22 18:35:00      170    3600      16.9 0.00137  #>  4 2020-08-31 09:56:00      170    3840      16.7 0.00182  #>  5 2015-11-21 20:27:00      150    3420      16.2 0.00228  #>  6 2017-05-03 06:19:00       90    4740      16.2 0.00273  #>  7 2020-09-16 14:44:00      160    6120      16.1 0.00319  #>  8 2020-07-23 23:17:00      186    4320      16.1 0.00364  #>  9 2019-07-25 06:32:00      300    5280      15.9 0.00410  #> 10 2020-09-15 18:01:00      160    5880      15.9 0.00455  #> # ℹ 2,187 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"robust-multivariate-scaling","dir":"","previous_headings":"","what":"Robust multivariate scaling","title":"Functions and Data Sets for ","text":"anomaly detection methods require data scaled first, observations scale. However, many scaling methods robust anomalies. mvscale() function provides multivariate robust scaling method, optionally takes account relationships betwen variables, uses robust estimates center, scale covariance default. centers removed using medians, scale function IQR, covariance matrix estimated using robust OGK estimate. data scaled using Cholesky decomposition inverse covariance. scaled data returned. scaled variables rotated orthogonal, renamed z1, z2, etc. Non-rotated scaling possible setting cov = NULL.","code":"mvscale(of) #> Warning in mvscale(of): Ignoring non-numeric columns: time #> # A tibble: 2,197 × 3 #>    time                     z1     z2 #>    <dttm>                <dbl>  <dbl> #>  1 2015-01-02 14:53:00  2.02   -1.33  #>  2 2015-01-09 23:55:00  0.0758  0.728 #>  3 2015-02-07 00:49:00 -1.64   -0.485 #>  4 2015-02-14 01:09:00 -1.86   -0.968 #>  5 2015-02-21 01:12:00 -1.25   -0.604 #>  6 2015-02-28 01:11:00 -2.57   -0.364 #>  7 2015-03-07 00:50:00 -3.63   -0.847 #>  8 2015-03-13 21:57:00 -0.913   0.606 #>  9 2015-03-13 23:37:00 -2.19   -0.726 #> 10 2015-03-20 22:26:00 -5.50   -3.51  #> # ℹ 2,187 more rows mvscale(of, cov = NULL) #> Warning in mvscale(of, cov = NULL): Ignoring non-numeric columns: time #> # A tibble: 2,197 × 3 #>    time                duration waiting #>    <dttm>                 <dbl>   <dbl> #>  1 2015-01-02 14:53:00    1.40   -1.24  #>  2 2015-01-09 23:55:00    0.316   0.676 #>  3 2015-02-07 00:49:00   -1.67   -0.451 #>  4 2015-02-14 01:09:00   -2.03   -0.900 #>  5 2015-02-21 01:12:00   -1.35   -0.562 #>  6 2015-02-28 01:11:00   -2.48   -0.338 #>  7 2015-03-07 00:50:00   -3.61   -0.787 #>  8 2015-03-13 21:57:00   -0.631   0.564 #>  9 2015-03-13 23:37:00   -2.25   -0.675 #> 10 2015-03-20 22:26:00   -6.22   -3.27  #> # ℹ 2,187 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Bagplot — gg_bagplot","title":"Bagplot — gg_bagplot","text":"Produces bivariate bagplot. bagplot analagous univariate boxplot, except two dimensions. Like boxplot, shows median, region containing 50% observations, region showing remaining observations outliers, outliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bagplot — gg_bagplot","text":"","code":"gg_bagplot(data, var1, var2, color = \"#00659e\", scatterplot = FALSE, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bagplot — gg_bagplot","text":"data data frame matrix containing data. var1 name first variable plot (bare expression). var2 name second variable plot (bare expression). color base color use median. colors generated mixture color white. scatterplot logical argument indicating regular bagplot required (FALSE), scatterplot colors required (TRUE). ... arguments passed compute.bagplot function.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bagplot — gg_bagplot","text":"ggplot object showing bagplot scatterplot data.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bagplot — gg_bagplot","text":"Rousseeuw, P. J., Ruts, ., & Tukey, J. W. (1999). bagplot: bivariate boxplot. American Statistician, 52(4), 382–387.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bagplot — gg_bagplot","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bagplot — gg_bagplot","text":"","code":"gg_bagplot(n01, v1, v2)  gg_bagplot(n01, v1, v2, scatterplot = TRUE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":null,"dir":"Reference","previous_headings":"","what":"Cricket batting data for international test players — cricket_batting","title":"Cricket batting data for international test players — cricket_batting","text":"dataset containing career batting statistics international test players (men women) 6 October 2021.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cricket batting data for international test players — cricket_batting","text":"","code":"cricket_batting"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cricket batting data for international test players — cricket_batting","text":"data frame 3754 rows 15 variables: Player Player name form \"initials surname\" Country Country played Start First year test playing career End Last year test playing career Matches Number matches played Innings Number innings batted NotOuts Number times Runs Total runs scored HighScore Highest score innings HighScoreNotOut highest score ? Average Batting average end career Hundreds Total number 100s scored Fifties Total number 50s scored Ducks Total number 0s scored Gender \"Men\" \"Women\"","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Cricket batting data for international test players — cricket_batting","text":"https://www.espncricinfo.com","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cricket batting data for international test players — cricket_batting","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cricket batting data for international test players — cricket_batting","text":"","code":"cricket_batting |>   filter(Innings > 20) |>   select(Player, Country, Matches, Runs, Average, Hundreds, Fifties, Ducks) |>   arrange(desc(Average)) #> # A tibble: 1,138 × 8 #>    Player        Country      Matches  Runs Average Hundreds Fifties Ducks #>    <chr>         <chr>          <int> <int>   <dbl>    <int>   <int> <int> #>  1 DG Bradman    Australia         52  6996    99.9       29      13     7 #>  2 AC Voges      Australia         20  1485    61.9        5       4     2 #>  3 SPD Smith     Australia         77  7540    61.8       27      31     5 #>  4 RG Pollock    South Africa      23  2256    61.0        7      11     1 #>  5 GA Headley    West Indies       22  2190    60.8       10       5     2 #>  6 M Labuschagne Australia         18  1885    60.8        5      10     1 #>  7 H Sutcliffe   England           54  4555    60.7       16      23     2 #>  8 E Bakewell    England           12  1078    59.9        4       7     0 #>  9 E Paynter     England           20  1540    59.2        4       7     3 #> 10 KF Barrington England           82  6806    58.7       20      35     5 #> # ℹ 1,128 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Create distributional object based on a specified density — dist_density","title":"Create distributional object based on a specified density — dist_density","text":"Creates distributional object using density specified pair vectors giving (x, f(x)). density assumed piecewise linear points provided, 0 outside range x.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create distributional object based on a specified density — dist_density","text":"","code":"dist_density(x, density)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create distributional object based on a specified density — dist_density","text":"x Numerical vector ordinates, list vectors. density Numerical vector density values, list vectors.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_density.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create distributional object based on a specified density — dist_density","text":"","code":"dist_density(seq(-4, 4, by = 0.01), dnorm(seq(-4, 4, by = 0.01))) #> <distribution[1]> #> [1] density[801]"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_kde.html","id":null,"dir":"Reference","previous_headings":"","what":"Create distributional object based on a kernel density estimate — dist_kde","title":"Create distributional object based on a kernel density estimate — dist_kde","text":"Creates distributional object using kernel density estimate Gaussian kernel obtained kde() function. bandwidth can specified; otherwise kde_bandwidth() function used. cdf, quantiles moments consistent kde. Generating random values kde equivalent smoothed bootstrap.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_kde.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create distributional object based on a kernel density estimate — dist_kde","text":"","code":"dist_kde(y, h = NULL, H = NULL, multiplier = 1, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_kde.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create distributional object based on a kernel density estimate — dist_kde","text":"y Numerical vector matrix data, list objects. list provided, objects dimension. e.g., vectors, matrices number columns. h Bandwidth univariate distribution. NULL, kde_bandwidth function used. H Bandwidth matrix multivariate distribution. NULL, kde_bandwidth function used. multiplier Multiplier bandwidth passed kde_bandwidth. Ignored h H specified. ... arguments passed kde.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_kde.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create distributional object based on a kernel density estimate — dist_kde","text":"","code":"dist_kde(c(rnorm(200), rnorm(100, 5)), multiplier = 2) #> <distribution[1]> #> [1] kde[1d, h=1.3] dist_kde(cbind(rnorm(200), rnorm(200, 5))) #> <distribution[1]> #> [1] kde[2d, H={(0.19, 0.024)', (0.024, 0.15)'}]"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":null,"dir":"Reference","previous_headings":"","what":"Wine prices and points — fetch_wine_reviews","title":"Wine prices and points — fetch_wine_reviews","text":"data set containing data wines 44 countries, taken Wine Enthusiast Magazine week 15 June 2017. data downloaded returned.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wine prices and points — fetch_wine_reviews","text":"","code":"fetch_wine_reviews()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Wine prices and points — fetch_wine_reviews","text":"data frame 110,203 rows 8 columns: country Country origin state State province origin region Region origin winery Name vineyard made wine variety Variety grape points Points allocated WineEnthusiast reviewer scale 0-100 price Price bottle wine $US year Year wine extracted title","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Wine prices and points — fetch_wine_reviews","text":"https://kaggle.com","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wine prices and points — fetch_wine_reviews","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wine prices and points — fetch_wine_reviews","text":"","code":"if (FALSE) { # \\dontrun{ wine_reviews <- fetch_wine_reviews() wine_reviews |>   ggplot(aes(x = points, y = price)) +   geom_jitter(height = 0, width = 0.2, alpha = 0.1) +   scale_y_log10() } # }"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":null,"dir":"Reference","previous_headings":"","what":"French mortality rates by age and sex — fr_mortality","title":"French mortality rates by age and sex — fr_mortality","text":"data set containing French mortality rates years 1816 1999, age sex.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"French mortality rates by age and sex — fr_mortality","text":"","code":"fr_mortality"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"French mortality rates by age and sex — fr_mortality","text":"data frame 31,648 rows 4 columns.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"French mortality rates by age and sex — fr_mortality","text":"Human Mortality Database https://www.mortality.org","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"French mortality rates by age and sex — fr_mortality","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"French mortality rates by age and sex — fr_mortality","text":"","code":"fr_mortality #> # A tibble: 31,648 × 4 #>     Year   Age Sex    Mortality #>    <int> <int> <chr>      <dbl> #>  1  1816     0 Female   0.187   #>  2  1816     1 Female   0.0467  #>  3  1816     2 Female   0.0339  #>  4  1816     3 Female   0.0229  #>  5  1816     4 Female   0.0160  #>  6  1816     5 Female   0.0138  #>  7  1816     6 Female   0.0121  #>  8  1816     7 Female   0.0104  #>  9  1816     8 Female   0.00891 #> 10  1816     9 Female   0.00760 #> # ℹ 31,638 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"Produce ggplot densities distributional objects 1 2 dimensions","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"","code":"gg_density(   object,   prob = seq(9)/10,   hdr = NULL,   show_points = FALSE,   show_mode = FALSE,   show_anomalies = FALSE,   colors = c(\"#0072b2\", \"#D55E00\", \"#009E73\", \"#CC79A7\", \"#E69F00\", \"#56B4E9\", \"#F0E442\",     \"#333333\"),   alpha = NULL,   jitter = FALSE,   ngrid = 501 )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"object distribution object distributional package dist_kde() prob Probability HDRs drawn. hdr Character string describing HDRs shown. Options \"none\", \"fill\", \"points\" \"contours\" (latter bivariate plots). NULL, \"none\" used univariate distributions \"contours\" bivariate. show_points TRUE, individual observations plotted. show_mode TRUE, mode distribution shown point. show_anomalies TRUE, observations surprisal probabilities less 0.005 shown black. colors Color palette use. length(colors) distributions, recycled. Default Okabe-Ito color palette. alpha Transparency points. Ignored show_points FALSE. Defaults min(1, 500/n), n number observations plotted. jitter univariate distributions, jitter TRUE show_points TRUE, small amount vertical jittering applied observations. Ignored bivariate distributions. ngrid Number grid points use density function.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"ggplot object.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"function produces ggplot density distributional object. univariate densities, produces line plot density function, optional ribbon showing highest density regions (HDRs) /observations. bivariate densities, produces ah HDR contour plot density function, observations optionally shown points. mode can also drawn point. combination hdr = \"fill\", show_points = TRUE, show_mode = TRUE, prob = c(0.5, 0.99) equivalent showing HDR boxplots.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"","code":"# Univariate densities kde <- dist_kde(c(rnorm(500), rnorm(500, 4, .5))) gg_density(kde,   hdr = \"fill\", prob = c(0.5, 0.95), color = \"#c14b14\",   show_mode = TRUE, show_points = TRUE, jitter = TRUE )  c(dist_normal(), kde) |>   gg_density(hdr = \"fill\", prob = c(0.5, 0.95))  # Bivariate density tibble(y1 = rnorm(5000), y2 = y1 + rnorm(5000)) |>   dist_kde() |>   gg_density(show_points = TRUE, alpha = 0.1, hdr = \"fill\")"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"Add ggplot layer densities distributional objects 1 dimension","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"","code":"gg_density_layer(object, scale = 1, ngrid = 501, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"object distribution object distributional package dist_kde() scale Scaling factor density function. ngrid Number grid points use density function. ... Additional arguments passed geom_line.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"ggplot layer","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"function adds ggplot layer density distributional object. univariate densities, adds line plot density function. bivariate densities, adds contour plot density function.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"","code":"dist_mixture(   dist_normal(-2, 1),   dist_normal(2, 1),   weights = c(1 / 3, 2 / 3) ) |>   gg_density() +   gg_density_layer(dist_normal(-2, 1), linetype = \"dashed\", scale = 1 / 3) +   gg_density_layer(dist_normal(2, 1), linetype = \"dashed\", scale = 2 / 3)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_hdrboxplot.html","id":null,"dir":"Reference","previous_headings":"","what":"HDR plot — gg_hdrboxplot","title":"HDR plot — gg_hdrboxplot","text":"Produces 1d 2d box plot HDR regions. darker regions contain observations higher probability, lighter regions contain points lower probability. Observations outside largest HDR shown individual points. Anomalies leave-one-surprisal probabilities less 0.005 optionally shown black.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_hdrboxplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HDR plot — gg_hdrboxplot","text":"","code":"gg_hdrboxplot(   data,   var1,   var2 = NULL,   prob = c(0.5, 0.99),   color = \"#0072b2\",   show_points = FALSE,   show_anomalies = TRUE,   scatterplot = show_points,   alpha = NULL,   jitter = TRUE,   ngrid = 501,   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_hdrboxplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"HDR plot — gg_hdrboxplot","text":"data data frame matrix containing data. var1 name first variable plot (bare expression). var2 Optionally, name second variable plot (bare expression). prob numeric vector specifying coverage probabilities HDRs. color base color use mode. Colors HDRs generated whitening color. show_points logical argument indicating regular HDR plot required (FALSE), whether show individual observations colors (TRUE). show_anomalies logical argument indicating surprisal anomalies shown (black). points leave-one-surprisal probability values less 0.005, lie outside 99% HDR region. scatterplot Equivalent show_points. Included compatibility gg_bagplot(). alpha Transparency points. Ignored show_points FALSE. Defaults min(1, 500/n), n number observations plotted. jitter logical value indicating points vertically jittered 1d box plots reduce overplotting. ngrid Number grid points use density function. ... arguments passed dist_kde.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_hdrboxplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"HDR plot — gg_hdrboxplot","text":"ggplot object showing HDR plot scatterplot data.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_hdrboxplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"HDR plot — gg_hdrboxplot","text":"original HDR boxplot proposed Hyndman (1996), can produced show_anomalies = FALSE, jitter = FALSE, alpha = 1, arguments set defaults.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_hdrboxplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"HDR plot — gg_hdrboxplot","text":"Hyndman, R J (1996) Computing Graphing Highest Density Regions, American Statistician, 50(2), 120–126. https://robjhyndman.com/publications/hdr/","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_hdrboxplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"HDR plot — gg_hdrboxplot","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_hdrboxplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"HDR plot — gg_hdrboxplot","text":"","code":"df <- data.frame(x = c(rnorm(1000), rnorm(1000, 5, 1), 10)) gg_hdrboxplot(df, x, show_anomalies = TRUE)  cricket_batting |>   filter(Innings > 20) |>   gg_hdrboxplot(Average)  oldfaithful |>   filter(duration < 7000, waiting < 7000) |>   gg_hdrboxplot(duration, waiting, show_points = TRUE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"GLOSH scores — glosh_scores","title":"GLOSH scores — glosh_scores","text":"Compute Global-Local Outlier Score Hierarchies. based hierarchical clustering minimum cluster size k. resulting outlier score measure anomalous observation . function uses dbscan::hdbscan calculation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GLOSH scores — glosh_scores","text":"","code":"glosh_scores(y, k = 10, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GLOSH scores — glosh_scores","text":"y Numerical matrix vector data k Minimum cluster size. Default: 5. ... Additional arguments passed dbscan::hdbscan","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GLOSH scores — glosh_scores","text":"Numerical vector containing GLOSH values","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"GLOSH scores — glosh_scores","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GLOSH scores — glosh_scores","text":"","code":"y <- c(rnorm(49), 5) glosh_scores(y) #>  [1] 0.294041184 0.656411173 0.244278846 0.000000000 0.266382606 0.590618555 #>  [7] 0.542127588 0.715781252 0.537873643 0.783946224 0.178881419 0.665407827 #> [13] 0.367072000 0.797652306 0.850926329 0.653407824 0.056007081 0.635155971 #> [19] 0.652614985 0.827186148 0.000000000 0.104812241 0.247450285 0.216076273 #> [25] 0.593656883 0.442679846 0.898654357 0.067972140 0.273819160 0.472366964 #> [31] 0.185379389 0.185379389 0.615896680 0.255303634 0.205018166 0.570359054 #> [37] 0.712700415 0.769523642 0.656117018 0.000000000 0.451488830 0.625406624 #> [43] 0.290851356 0.179834758 0.000000000 0.179834758 0.104466313 0.629075489 #> [49] 0.004060706 0.960996766"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Grubbs' test (proposed 1950) identifies possible anomalies univariate data using z-scores assuming data come normal distribution. Dixon's test (also 1950) compares difference largest two values range data. Critical values Dixon's test computed using simulation interpolation using quadratic model logit(alpha) log(log(n)).","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"","code":"grubbs_anomalies(y, alpha = 0.05)  dixon_anomalies(y, alpha = 0.05, two_sided = TRUE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"y numerical vector observations alpha size test. two_sided TRUE, minimum maximums considered. Otherwise maximum used. (Take negative values consider minimum two_sided=FALSE.)","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"logical vector","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Grubbs' test based z-scores, point identified anomaly associated absolute z-score greater threshold value. vector logical values returned, TRUE indicates anomaly. version Grubbs' test looks outliers anywhere sample. Grubbs' original test came several variations looked one outlier, two outliers one tail, two outliers opposite tails. variations implemented grubbs.test function. Dixon's test considers maximum (possibly minimum) potential outliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Grubbs, F. E. (1950). Sample criteria testing outlying observations. Annals Mathematical Statistics, 21(1), 27–58. Dixon, W. J. (1950). Analysis extreme values. Annals Mathematical Statistics, 21(4), 488–506.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"","code":"x <- c(rnorm(1000), 5:10) tibble(x = x) |> filter(grubbs_anomalies(x)) #> # A tibble: 6 × 1 #>       x #>   <dbl> #> 1     5 #> 2     6 #> 3     7 #> 4     8 #> 5     9 #> 6    10 tibble(x = x) |> filter(dixon_anomalies(x)) #> # A tibble: 0 × 1 #> # ℹ 1 variable: x <dbl> y <- c(rnorm(1000), 5) tibble(y = y) |> filter(grubbs_anomalies(y)) #> # A tibble: 1 × 1 #>       y #>   <dbl> #> 1     5 tibble(y = y) |> filter(dixon_anomalies(y)) #> # A tibble: 1 × 1 #>       y #>   <dbl> #> 1     5"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify anomalies using the Hampel filter — hampel_anomalies","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"Hampel filter designed find anomalies time series data using mean absolute deviations vicinity observation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"","code":"hampel_anomalies(y, bandwidth, k = 3)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"y numeric vector containing time series bandwidth integer width window around observation k numeric number standard deviations declare outlier","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"logical vector identifying observations anomalies.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"First, moving median calculated using windows size 2 * bandwidth + 1. median absolute deviations moving median calculated moving windows. point declared anomaly MAD value k standard deviations. MAD converted standard deviation using MAD * 1.482602, holds normally distributed data. first bandwidth last bandwidth observations declared anomalies.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"","code":"set.seed(1) df <- tibble(   time = seq(41),   y = c(rnorm(20), 5, rnorm(20)) ) |>   mutate(hampel = hampel_anomalies(y, bandwidth = 3, k = 4)) df |> ggplot(aes(x = time, y = y)) +   geom_line() +   geom_point(data = df |> filter(hampel), col = \"red\")"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Table of Highest Density Regions — hdr_table","title":"Table of Highest Density Regions — hdr_table","text":"Compute table highest density regions (HDR) distributional object. HDRs returned tibble one row per interval columns: prob (giving probability coverage), density (value density boundary HDR), one dimensional density functions, tibble also columns lower (lower ends intervals), upper (upper ends intervals).","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Table of Highest Density Regions — hdr_table","text":"","code":"hdr_table(object, prob)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Table of Highest Density Regions — hdr_table","text":"object Distributional object returned dist_kde() prob Vector probabilities giving HDR coverage (0 1)","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Table of Highest Density Regions — hdr_table","text":"tibble","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Table of Highest Density Regions — hdr_table","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Table of Highest Density Regions — hdr_table","text":"","code":"# Univariate HDRs c(dist_normal(), dist_kde(c(rnorm(100), rnorm(100, 3, 1)))) |>   hdr_table(c(0.5, 0.95)) #> # A tibble: 5 × 5 #>    prob distribution     lower upper density #>   <dbl> <chr>            <dbl> <dbl>   <dbl> #> 1  0.5  N(0, 1)         -0.674 0.674  0.213  #> 2  0.95 N(0, 1)         -1.96  1.96   0.0521 #> 3  0.5  kde[1d, h=0.65] -0.672 1.06   0.213  #> 4  0.5  kde[1d, h=0.65]  2.00  3.11   0.213  #> 5  0.95 kde[1d, h=0.65] -1.69  5.04   0.0521 dist_kde(oldfaithful$duration) |> hdr_table(0.95) #> # A tibble: 2 × 5 #>    prob distribution lower upper density #>   <dbl> <chr>        <dbl> <dbl>   <dbl> #> 1  0.95 kde[1d, h=5]  115.  155. 0.00161 #> 2  0.95 kde[1d, h=5]  197.  268. 0.00161 # Bivariate HDRs dist_kde(oldfaithful[, c(\"duration\", \"waiting\")]) |> hdr_table(0.90) #> # A tibble: 1 × 3 #>   distribution                                      prob density #>   <chr>                                            <dbl>   <dbl> #> 1 kde[2d, H={(40, 3.3e+02)', (3.3e+02, 2.1e+04)'}]   0.9       0"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"Robust bandwidth estimation kernel density estimation","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"","code":"kde_bandwidth(data, multiplier = 1)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"data numeric matrix data frame. multiplier Bandwidths chosen using robust version normal reference rule multiplied constant. default 1.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"matrix bandwidths (scalar case univariate data).","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"","code":"# Univariate bandwidth calculation kde_bandwidth(oldfaithful$duration) #> [1] 5.01193 # Bivariate bandwidth calculation kde_bandwidth(oldfaithful[, 2:3]) #>           [,1]       [,2] #> [1,]  40.35726   332.8928 #> [2,] 332.89280 21096.1493"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Local outlier factors — lof_scores","title":"Local outlier factors — lof_scores","text":"Compute local outlier factors using k nearest neighbours. local outlier factor measure anomalous observation based density neighbouring points. function uses dbscan::lof calculation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local outlier factors — lof_scores","text":"","code":"lof_scores(y, k = 10, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local outlier factors — lof_scores","text":"y Numerical matrix vector data k Number neighbours include. Default: 5. ... Additional arguments passed dbscan::lof","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local outlier factors — lof_scores","text":"Numerical vector containing LOF values","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Local outlier factors — lof_scores","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local outlier factors — lof_scores","text":"","code":"y <- c(rnorm(49), 5) lof_scores(y) #>  [1] 1.0406669 0.9900373 1.0117207 1.0766228 0.9536460 2.2297450 1.0362703 #>  [8] 0.9299435 1.0264040 1.0380001 1.5644976 1.9123641 1.1764795 0.9172575 #> [15] 3.4947121 1.0484774 1.2941360 1.0477277 1.2207751 1.0002774 1.2016687 #> [22] 1.0273918 1.0247039 1.0578666 0.9941317 0.9947802 1.1246896 0.9962224 #> [29] 1.0277018 0.9823940 0.9602361 1.0093079 2.4805006 2.4221470 0.9603850 #> [36] 0.9691792 0.9975073 1.0044611 0.9195883 1.1647098 1.0180839 3.3331210 #> [43] 0.9697781 0.9493904 1.2305515 1.0181051 0.9810810 0.9752703 0.9794090 #> [50] 7.8224327"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Lookout probabilities — lookout_prob","title":"Lookout probabilities — lookout_prob","text":"lookout algorithm (Kandanaarachchi & Hyndman, 2022) computes leave-one-surprisal probabilities kernel density estimate using Generalized Pareto distribution. kernel density estimate uses bandwidth based topological data analysis quadratic kernel. similar identical using surprisals loo = TRUE approximation = \"gdp\". low probability indicates likely anomaly.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lookout probabilities — lookout_prob","text":"","code":"lookout_prob(object, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lookout probabilities — lookout_prob","text":"object numerical data set. ... arguments passed lookout.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lookout probabilities — lookout_prob","text":"numerical vector containing lookout probabilities","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Lookout probabilities — lookout_prob","text":"Sevvandi Kandanaarachchi & Rob J Hyndman (2022) \"Leave-one-kernel density estimates outlier detection\", J Computational & Graphical Statistics, 31(2), 586-599. https://robjhyndman.com/publications/lookout/","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Lookout probabilities — lookout_prob","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lookout probabilities — lookout_prob","text":"","code":"# Univariate data tibble(   y = c(5, rnorm(49)),   lookout = lookout_prob(y) ) #> # A tibble: 50 × 2 #>          y lookout #>      <dbl>   <dbl> #>  1  5        0     #>  2 -1.21     1     #>  3  2.18     0.717 #>  4 -0.435    1     #>  5 -2.05     1     #>  6 -0.0359   1     #>  7  0.0235   1     #>  8  0.190    1     #>  9 -0.470    1     #> 10 -0.483    1     #> # ℹ 40 more rows # Bivariate data tibble(   x = rnorm(50),   y = c(5, rnorm(49)),   lookout = lookout_prob(cbind(x, y)) ) #> # A tibble: 50 × 3 #>          x      y lookout #>      <dbl>  <dbl>   <dbl> #>  1 -1.74    5      0.0510 #>  2  0.872  -1.41   1      #>  3 -1.43   -0.863  1      #>  4 -0.293   0.343  1      #>  5  0.913  -0.315  1      #>  6  1.50    1.01   0.966  #>  7 -1.75   -0.576  0.799  #>  8  1.69    1.43   0.635  #>  9 -0.0708 -0.507  1      #> 10 -0.304  -0.543  1      #> # ℹ 40 more rows # Using a regression model of <- oldfaithful |> filter(duration < 7200, waiting < 7200) fit_of <- lm(waiting ~ duration, data = of) broom::augment(fit_of) |>   mutate(lookout = lookout_prob(.std.resid)) |>   arrange(lookout) #> # A tibble: 2,197 × 9 #>    waiting duration .fitted .resid     .hat .sigma .cooksd .std.resid lookout #>      <dbl>    <dbl>   <dbl>  <dbl>    <dbl>  <dbl>   <dbl>      <dbl>   <dbl> #>  1    5700        1   2837.  2863. 0.0138     424. 0.316         6.73  0      #>  2    6060      120   4274.  1786. 0.00348    427. 0.0304        4.17  0.0194 #>  3    6971      210   5360.  1611. 0.000541   427. 0.00383       3.76  0.0265 #>  4    7080      220   5481.  1599. 0.000473   427. 0.00329       3.73  0.0271 #>  5    3600      170   4877. -1277. 0.00133    428. 0.00593      -2.98  0.0285 #>  6    4500      241   5735. -1235. 0.000497   428. 0.00206      -2.88  0.0340 #>  7    6480      180   4998.  1482. 0.00106    428. 0.00633       3.46  0.0351 #>  8    6618      192   5143.  1475. 0.000795   428. 0.00471       3.44  0.0358 #>  9    6720      201   5252.  1468. 0.000647   428. 0.00380       3.43  0.0364 #> 10    3420      150   4636. -1216. 0.00204    428. 0.00823      -2.84  0.0368 #> # ℹ 2,187 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute robust multivariate scaled data — mvscale","title":"Compute robust multivariate scaled data — mvscale","text":"multivariate version base::scale(), takes account covariance matrix data, uses robust estimates center, scale covariance default. centers removed using medians, scale function IQR, covariance matrix estimated using robust OGK estimate. data scaled using Cholesky decomposition inverse covariance. scaled data returned. useful computing pairwise Mahalanobis distances.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute robust multivariate scaled data — mvscale","text":"","code":"mvscale(   object,   center = stats::median,   scale = robustbase::s_Qn,   cov = robustbase::covOGK,   warning = TRUE )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute robust multivariate scaled data — mvscale","text":"object vector, matrix, data frame containing numerical data. center function compute center numerical variable. Set NULL centering required. scale function scale numerical variable. cov = robustbase::covOGK, passed sigmamu argument. cov function compute covariance matrix. Set NULL rotation required. warning warning issued non-numeric columns ignored?","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute robust multivariate scaled data — mvscale","text":"vector, matrix data frame size class object, numerical variables replaced scaled versions.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute robust multivariate scaled data — mvscale","text":"Optionally, centering scaling can done variable separately, rotation data, setting cov = NULL. Also optionally, non-robust methods can used specifying center = mean, scale = stats::sd, cov = stats::cov. non-numeric columns retained warning.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute robust multivariate scaled data — mvscale","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute robust multivariate scaled data — mvscale","text":"","code":"# Univariate z-scores (no rotation) mvscale(oldfaithful, center = mean, scale = sd, cov = NULL, warning = FALSE) #> # A tibble: 2,261 × 3 #>    time                duration waiting #>    <dttm>                 <dbl>   <dbl> #>  1 2015-01-02 14:53:00   0.261  -0.258  #>  2 2015-01-09 23:55:00   0.104  -0.0337 #>  3 2015-02-07 00:49:00  -0.185  -0.166  #>  4 2015-02-14 01:09:00  -0.237  -0.218  #>  5 2015-02-21 01:12:00  -0.139  -0.179  #>  6 2015-02-28 01:11:00  -0.303  -0.153  #>  7 2015-03-07 00:50:00  -0.467  -0.205  #>  8 2015-03-13 21:57:00  -0.0340 -0.0469 #>  9 2015-03-13 23:37:00  -0.270  -0.192  #> 10 2015-03-20 22:26:00  -0.847  -0.496  #> # ℹ 2,251 more rows # Non-robust scaling with rotation mvscale(oldfaithful, center = mean, cov = stats::cov, warning = FALSE) #> # A tibble: 2,261 × 3 #>    time                     z1      z2 #>    <dttm>                <dbl>   <dbl> #>  1 2015-01-02 14:53:00  0.266  -0.258  #>  2 2015-01-09 23:55:00  0.104  -0.0337 #>  3 2015-02-07 00:49:00 -0.182  -0.166  #>  4 2015-02-14 01:09:00 -0.234  -0.218  #>  5 2015-02-21 01:12:00 -0.136  -0.179  #>  6 2015-02-28 01:11:00 -0.300  -0.153  #>  7 2015-03-07 00:50:00 -0.463  -0.205  #>  8 2015-03-13 21:57:00 -0.0332 -0.0469 #>  9 2015-03-13 23:37:00 -0.267  -0.192  #> 10 2015-03-20 22:26:00 -0.839  -0.496  #> # ℹ 2,251 more rows mvscale(oldfaithful, warning = FALSE) #> # A tibble: 2,261 × 3 #>    time                     z1     z2 #>    <dttm>                <dbl>  <dbl> #>  1 2015-01-02 14:53:00  1.93   -1.25  #>  2 2015-01-09 23:55:00  0.0615  0.684 #>  3 2015-02-07 00:49:00 -1.55   -0.456 #>  4 2015-02-14 01:09:00 -1.74   -0.910 #>  5 2015-02-21 01:12:00 -1.18   -0.568 #>  6 2015-02-28 01:11:00 -2.43   -0.342 #>  7 2015-03-07 00:50:00 -3.42   -0.796 #>  8 2015-03-13 21:57:00 -0.873   0.570 #>  9 2015-03-13 23:37:00 -2.07   -0.682 #> 10 2015-03-20 22:26:00 -5.15   -3.30  #> # ℹ 2,251 more rows # Robust Mahalanobis distances oldfaithful |>   select(-time) |>   mvscale() |>   head(5) |>   dist() #>           1         2         3         4 #> 2 2.6919702                               #> 3 3.5671576 1.9718769                     #> 4 3.6897826 2.4089549 0.4950822           #> 5 3.1820624 1.7618897 0.3861243 0.6617578"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate standard normal data — n01","title":"Multivariate standard normal data — n01","text":"synthetic data set containing 1000 observations 10 variables generated independent standard normal distributions.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate standard normal data — n01","text":"","code":"n01"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Multivariate standard normal data — n01","text":"data frame 1000 rows 10 columns.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate standard normal data — n01","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate standard normal data — n01","text":"","code":"n01 #> # A tibble: 1,000 × 10 #>        v1      v2      v3      v4     v5     v6      v7     v8     v9     v10 #>     <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>  <dbl>  <dbl>   <dbl> #>  1 -0.626  1.13   -0.886   0.739  -1.13  -1.52  -0.619  -1.33   0.264 -1.22   #>  2  0.184  1.11   -1.92    0.387   0.765  0.629 -1.11    0.952 -0.829 -0.946  #>  3 -0.836 -0.871   1.62    1.30    0.571 -1.68  -2.17    0.860 -1.46   0.0914 #>  4  1.60   0.211   0.519  -0.804  -1.35   1.18  -0.0313  1.06   1.68   0.701  #>  5  0.330  0.0694 -0.0558 -1.60   -2.03   1.12  -0.260  -0.351 -1.54   0.673  #>  6 -0.820 -1.66    0.696   0.933   0.590 -1.24   0.534  -0.131 -0.191  1.27   #>  7  0.487  0.811   0.0535  1.81   -1.41  -1.23  -0.559   0.764  1.02  -1.45   #>  8  0.738 -1.91   -1.31   -0.0565  1.61   0.598  1.61   -0.494  0.547  1.42   #>  9  0.576 -1.25   -2.12    1.89    1.84   0.299  0.557   1.11   0.755 -1.59   #> 10 -0.305  0.998  -0.208   1.58    1.37  -0.110  0.186   1.46  -0.420  0.246  #> # ℹ 990 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":null,"dir":"Reference","previous_headings":"","what":"Old faithful eruption data — oldfaithful","title":"Old faithful eruption data — oldfaithful","text":"data set containing data recorded eruptions Old Faithful Geyser Yellowstone National Park, Wyoming, USA, 1 January 2015 1 October 2021. Recordings incomplete, especially winter months observers may present.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Old faithful eruption data — oldfaithful","text":"","code":"oldfaithful"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Old faithful eruption data — oldfaithful","text":"data frame 2261 rows 3 columns: time Time eruption started duration Duration eruption seconds waiting Time following eruption","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Old faithful eruption data — oldfaithful","text":"https://geysertimes.org","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Old faithful eruption data — oldfaithful","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Old faithful eruption data — oldfaithful","text":"","code":"oldfaithful |>   filter(duration < 7000, waiting < 7000) |>   ggplot(aes(x = duration, y = waiting)) +   geom_point()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"Peirce's criterion Chauvenet's criterion proposed 1800s way determining observations rejected univariate sample.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"","code":"peirce_anomalies(y)  chauvenet_anomalies(y)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"y numerical vector observations","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"logical vector","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"functions take univariate sample y return logical vector indicating observations considered anomalies according either Peirce's criterion Chauvenet's criterion.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"Peirce, B. (1852). Criterion rejection doubtful observations. Astronomical Journal, 2(21), 161–163. Chauvenet, W. (1863). 'Method least squares'. Appendix Manual Spherical Practical Astronomy, Vol.2, Lippincott, Philadelphia, pp.469-566.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"","code":"y <- rnorm(1000) tibble(y = y) |> filter(peirce_anomalies(y)) #> # A tibble: 0 × 1 #> # ℹ 1 variable: y <dbl> tibble(y = y) |> filter(chauvenet_anomalies(y)) #> # A tibble: 0 × 1 #> # ℹ 1 variable: y <dbl>"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. ggplot2 autoplot","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Stray anomalies — stray_anomalies","title":"Stray anomalies — stray_anomalies","text":"Test observations anomalies according stray algorithm.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stray anomalies — stray_anomalies","text":"","code":"stray_anomalies(y, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stray anomalies — stray_anomalies","text":"y vector, matrix, data frame consisting numerical variables. ... arguments passed find_HDoutliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stray anomalies — stray_anomalies","text":"Numerical vector containing logical values indicating observation identified anomaly using stray algorithm.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stray anomalies — stray_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stray anomalies — stray_anomalies","text":"","code":"# Univariate data y <- c(6, rnorm(49)) stray_anomalies(y) #>  [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [49] FALSE FALSE # Bivariate data y <- cbind(rnorm(50), c(5, rnorm(49))) stray_anomalies(y) #>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [49] FALSE FALSE"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Stray scores — stray_scores","title":"Stray scores — stray_scores","text":"Compute stray scores indicating anomalous observation .","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stray scores — stray_scores","text":"","code":"stray_scores(y, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stray scores — stray_scores","text":"y vector, matrix, data frame consisting numerical variables. ... arguments passed find_HDoutliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stray scores — stray_scores","text":"Numerical vector containing stray scores.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stray scores — stray_scores","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stray scores — stray_scores","text":"","code":"# Univariate data y <- c(6, rnorm(49)) scores <- stray_scores(y) threshold <- stray::find_threshold(scores, alpha = 0.01, outtail = \"max\", p = 0.5, tn = 50) which(scores > threshold) #> integer(0)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.html","id":null,"dir":"Reference","previous_headings":"","what":"Surprisals — surprisals","title":"Surprisals — surprisals","text":"Compute surprisals surprisal probabilities model data set. surprisal given \\(s = -\\log f(y)\\) \\(f\\) density probability mass function estimated assumed distribution, \\(y\\) observation. surprisal probability probability surprisal least extreme \\(s\\). surprisal probabilities may computed three different ways. Given distribution used compute surprisal values. option, surprisal probabilities equal 1 minus coverage probability largest HDR contains value. Surprisal probabilities smaller 1e-6 returned 1e-6. Using Generalized Pareto Distribution fitted extreme surprisal values (probability less threshold_probability). option used approximation = \"gpd\". surprisal probabilities greater threshold_probability, value threshold_probability returned. option, distribution used computing surprisal values determining probabilities. Due extreme value theory, resulting probabilities relatively insensitive distribution used computing surprisal values. Empirically proportion observations greater surprisal values. option used approxiation = \"empirical\". also insensitive distribution used computing surprisal values.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Surprisals — surprisals","text":"","code":"surprisals(   object,   probability = TRUE,   approximation = c(\"none\", \"gpd\", \"empirical\"),   threshold_probability = 0.1,   ... )  # Default S3 method surprisals(   object,   probability = TRUE,   approximation = c(\"none\", \"gpd\", \"empirical\"),   threshold_probability = 0.1,   distribution = dist_kde(object, multiplier = 2, ...),   loo = FALSE,   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Surprisals — surprisals","text":"object model numerical data set probability surprisal probabilities computed, surprisal values? approximation Character string specifying approximation use computing surprisal probabilities. Ignored probability = FALSE. : none specifies approximation used; gpd specifies  Generalized Pareto distribution used; empirical specifies probabilities estimated empirically. threshold_probability Probability threshold computing GPD approximation. probability GPD fitted. used approximation = \"gpd\"). ... arguments passed appropriate method. distribution distribution object. provided, kernel density estimate computed data object. loo leave-one-surprisals computed?","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Surprisals — surprisals","text":"numerical vector containing surprisals surprisal probabilities.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Surprisals — surprisals","text":"distribution provided, kernel density estimate computed. leave-one-surprisals (LOO surprisals) obtained estimating kernel density estimate using observations.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Surprisals — surprisals","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Surprisals — surprisals","text":"","code":"# surprisals computed from bivariate data set oldfaithful |>   filter(duration < 7000, waiting < 7000) |>   mutate(     loo_fscores = surprisals(cbind(duration, waiting), loo = TRUE)   ) #> # A tibble: 2,189 × 4 #>    time                duration waiting loo_fscores #>    <dttm>                 <dbl>   <dbl>       <dbl> #>  1 2015-01-02 14:53:00      271    5040      0.0918 #>  2 2015-01-09 23:55:00      247    6060      0.718  #>  3 2015-02-07 00:49:00      203    5460      0.194  #>  4 2015-02-14 01:09:00      195    5221      0.157  #>  5 2015-02-21 01:12:00      210    5401      0.283  #>  6 2015-02-28 01:11:00      185    5520      0.220  #>  7 2015-03-07 00:50:00      160    5281      0.249  #>  8 2015-03-13 21:57:00      226    6000      0.395  #>  9 2015-03-13 23:37:00      190    5341      0.139  #> 10 2015-03-20 22:26:00      102    3961      0.0955 #> # ℹ 2,179 more rows # Univariate data tibble(   y = c(5, rnorm(49)),   p_kde = surprisals(y, loo = TRUE),   p_normal = surprisals(y, distribution = dist_normal()),   p_zscore = 2 * (1 - pnorm(abs(y))) ) #> # A tibble: 50 × 4 #>         y    p_kde    p_normal    p_zscore #>     <dbl>    <dbl>       <dbl>       <dbl> #>  1  5     0.000292 0.000000573 0.000000573 #>  2 -0.695 0.567    0.487       0.487       #>  3  0.540 0.706    0.590       0.590       #>  4 -0.944 0.448    0.345       0.345       #>  5  1.40  0.330    0.162       0.162       #>  6 -0.982 0.431    0.326       0.326       #>  7  1.32  0.359    0.188       0.188       #>  8 -0.231 0.804    0.817       0.817       #>  9 -0.824 0.504    0.410       0.410       #> 10 -0.480 0.677    0.631       0.631       #> # ℹ 40 more rows tibble(   y = n01$v1,   prob1 = surprisals(y, loo = TRUE),   prob2 = surprisals(y, approximation = \"gpd\"),   prob3 = surprisals(y, distribution = dist_normal()),   prob4 = surprisals(y, distribution = dist_normal(), approximation = \"gpd\") ) |>   arrange(prob1) #> # A tibble: 1,000 × 5 #>        y    prob1    prob2    prob3    prob4 #>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl> #>  1  3.81 0.000675 0.000113 0.000139 0.000135 #>  2  3.06 0.00694  0.00194  0.00225  0.00261  #>  3 -3.01 0.0109   0.00362  0.00263  0.00308  #>  4 -3.00 0.0112   0.00376  0.00273  0.00320  #>  5 -2.94 0.0129   0.00456  0.00328  0.00389  #>  6 -2.89 0.0146   0.00538  0.00387  0.00461  #>  7  2.68 0.0199   0.00810  0.00746  0.00913  #>  8  2.65 0.0214   0.00887  0.00807  0.00991  #>  9 -2.60 0.0283   0.0128   0.00943  0.0116   #> 10 -2.59 0.0285   0.0130   0.00953  0.0118   #> # ℹ 990 more rows # Bivariate data tibble(   x = rnorm(50),   y = c(5, rnorm(49)),   prob = surprisals(cbind(x, y)),   lookout = lookout_prob(cbind(x, y)) ) #> # A tibble: 50 × 4 #>          x      y  prob lookout #>      <dbl>  <dbl> <dbl>   <dbl> #>  1  0.460   5      0.02       0 #>  2 -0.925  -0.819  0.4        1 #>  3  0.181   0.189  0.9        1 #>  4  0.777   0.204  0.84       1 #>  5 -0.522  -0.367  0.62       1 #>  6 -0.191  -0.985  0.56       1 #>  7  0.535   0.293  0.88       1 #>  8 -0.292  -0.369  0.78       1 #>  9  0.0992 -0.714  0.7        1 #> 10  1.60    0.107  0.42       1 #> # ℹ 40 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Surprisals computed from a model — surprisals.lm","title":"Surprisals computed from a model — surprisals.lm","text":"Surprisals computed model","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Surprisals computed from a model — surprisals.lm","text":"","code":"# S3 method for class 'lm' surprisals(   object,   probability = TRUE,   approximation = c(\"none\", \"gpd\", \"empirical\"),   threshold_probability = 0.1,   loo = FALSE,   ... )  # S3 method for class 'gam' surprisals(   object,   probability = TRUE,   approximation = c(\"none\", \"gpd\", \"empirical\"),   threshold_probability = 0.1,   loo = FALSE,   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Surprisals computed from a model — surprisals.lm","text":"object model object returned lm, gam. probability surprisal probabilities computed, surprisal values? approximation Character string specifying approximation use computing surprisal probabilities. Ignored probability = FALSE. : none specifies approximation used; gpd specifies  Generalized Pareto distribution used; empirical specifies probabilities estimated empirically. threshold_probability Probability threshold computing GPD approximation. probability GPD fitted. used approximation = \"gpd\"). loo leave-one-surprisals computed? ... arguments ignored.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Surprisals computed from a model — surprisals.lm","text":"","code":"# surprisals computed from linear model of <- oldfaithful |>   filter(duration < 7200, waiting < 7200) lm_of <- lm(waiting ~ duration, data = of) of |>   mutate(     fscore = surprisals(lm_of),     loo_fscore = surprisals(lm_of, loo = TRUE),     # lookout_prob = lookout(surprisals = fscore, loo_scores = loo_fscore)   ) |>   ggplot(aes(     x = duration, y = waiting,     color = loo_fscore > quantile(loo_fscore, 0.99)   )) +   geom_point()  # surprisals computed from GAM of <- oldfaithful |>   filter(duration > 1, duration < 7200, waiting < 7200) gam_of <- mgcv::gam(waiting ~ s(duration), data = of) of |>   mutate(fscore = surprisals(gam_of)) #> # A tibble: 2,196 × 4 #>    time                duration waiting fscore #>    <dttm>                 <dbl>   <dbl>  <dbl> #>  1 2015-01-02 14:53:00      271    5040  0.119 #>  2 2015-01-09 23:55:00      247    6060  0.402 #>  3 2015-02-07 00:49:00      203    5460  0.890 #>  4 2015-02-14 01:09:00      195    5221  0.717 #>  5 2015-02-21 01:12:00      210    5401  0.787 #>  6 2015-02-28 01:11:00      185    5520  0.948 #>  7 2015-03-07 00:50:00      160    5281  0.817 #>  8 2015-03-13 21:57:00      226    6000  0.361 #>  9 2015-03-13 23:37:00      190    5341  0.862 #> 10 2015-03-20 22:26:00      102    3961  0.960 #> # ℹ 2,186 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird-package.html","id":null,"dir":"Reference","previous_headings":"","what":"weird: Functions and Data Sets for ","title":"weird: Functions and Data Sets for ","text":"functions data sets required examples book Hyndman (2024) \"Weird: Anomaly Detection Using R\" https://OTexts.com/weird/. packages needed run examples also loaded.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"weird: Functions and Data Sets for ","text":"Maintainer: Rob Hyndman Rob.Hyndman@monash.edu (ORCID) [copyright holder] contributors: RStudio [copyright holder]","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":null,"dir":"Reference","previous_headings":"","what":"Conflicts between weird packages and other packages — weird_conflicts","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"function lists conflicts packages weird collection packages loaded.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"","code":"weird_conflicts()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"list object class weird_conflicts.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"conflicts deliberately ignored: intersect, union, setequal, setdiff dplyr; intersect, union, setdiff, .difftime lubridate. functions make base equivalents generic, negatively affect existing code.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"","code":"weird_conflicts() #> ── Conflicts ──────────────────────────────────────────────── weird_conflicts ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":null,"dir":"Reference","previous_headings":"","what":"List all packages loaded by weird — weird_packages","title":"List all packages loaded by weird — weird_packages","text":"List packages loaded weird","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List all packages loaded by weird — weird_packages","text":"","code":"weird_packages(include_self = FALSE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List all packages loaded by weird — weird_packages","text":"include_self Include weird list?","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List all packages loaded by weird — weird_packages","text":"character vector package names.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List all packages loaded by weird — weird_packages","text":"","code":"weird_packages() #>  [1] \"aplpack\"        \"broom\"          \"cli\"            \"crayon\"         #>  [5] \"dbscan\"         \"distributional\" \"dplyr\"          \"evd\"            #>  [9] \"ggplot2\"        \"grDevices\"      \"interp\"         \"ks\"             #> [13] \"lookout\"        \"mvtnorm\"        \"purrr\"          \"rlang\"          #> [17] \"robustbase\"     \"rstudioapi\"     \"stray\"          \"tibble\"         #> [21] \"vctrs\""},{"path":"https://pkg.robjhyndman.com/weird-package/news/index.html","id":"weird-development-version","dir":"Changelog","previous_headings":"","what":"weird (development version)","title":"weird (development version)","text":"Added fr_mortality data set Refactored package use distributional objects Removed as_kde() autoplot.kde() Added gg_density() gg_density_layer() Added surprisals() surprisal_prob() Renamed lookout() lookout_prob() Added hampel_anomalies() mvscale() resilient weird data","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/news/index.html","id":"weird-102","dir":"Changelog","previous_headings":"","what":"weird 1.0.2","title":"weird 1.0.2","text":"CRAN release: 2024-01-24 Removed wine_reviews dataset created fetch_wine_reviews() function. Bug fixes.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/news/index.html","id":"weird-100","dir":"Changelog","previous_headings":"","what":"weird 1.0.0","title":"weird 1.0.0","text":"CRAN release: 2024-01-12 Initial CRAN submission.","code":""}]
