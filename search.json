[{"path":"https://pkg.robjhyndman.com/weird-package/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rob Hyndman. Author, maintainer, copyright holder. RStudio. Copyright holder.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hyndman RJ (2024). weird: Functions Data Sets \"Weird: Anomaly Detection Using R\" Rob J Hyndman. R package version 1.0.2.9000, https://pkg.robjhyndman.com/weird-package/. Hyndman RJ (2024). Weird: Anomaly Detection Using R. OTexts, Melbourne, Australia. preparation, https://OTexts.com/weird/.","code":"@Manual{,   title = {{weird: Functions and Data Sets for \"That's Weird: Anomaly Detection Using R\" by Rob J Hyndman}},   author = {Rob J Hyndman},   year = {2024},   note = {R package version 1.0.2.9000},   url = {https://pkg.robjhyndman.com/weird-package/}, } @Book{,   title = {That's Weird: Anomaly Detection Using {R}},   author = {Rob J Hyndman},   year = {2024},   note = {In preparation},   publisher = {OTexts},   address = {Melbourne, Australia},   url = {https://OTexts.com/weird/}, }"},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Functions and Data Sets for ","text":"weird package contains functions data used book ’s Weird: Anomaly Detection Using R Rob J Hyndman. also loads several packages needed analysis described book.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Functions and Data Sets for ","text":"can install stable version CRAN : can install development version weird GitHub :","code":"install.packages(\"weird\") # install.packages(\"devtools\") devtools::install_github(\"robjhyndman/weird-package\")"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Functions and Data Sets for ","text":"library(weird) load following packages: dplyr, data manipulation. ggplot2, data visualisation. ks, fitting models producing forecasts. also get condensed summary conflicts packages loaded:","code":"library(weird) #> ── Attaching packages ────────────────────────────────────── weird 1.0.2.9000 ── #> ✔ dplyr          1.1.4          ✔ distributional 0.4.0.9000 #> ✔ ggplot2        3.5.1 #> ── Conflicts ──────────────────────────────────────────────── weird_conflicts ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag()"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"example-old-faithful-geyser-data","dir":"","previous_headings":"","what":"Example: Old Faithful Geyser data","title":"Functions and Data Sets for ","text":"oldfaithful data set contains eruption data Old Faithful Geyser Yellowstone National Park, Wyoming, USA, 1 January 2015 1 October 2021. data obtained geysertimes.org website. Recordings incomplete, especially winter months observers may present. also appear recording errors. data set contains 2261 observations 3 variables: time giving time eruption began, duration giving length eruption seconds, waiting giving time next eruption seconds. analysis , omit eruption duration greater 1 hour likely recording error. long waiting values probably due omitted eruptions, also omit eruptions waiting greater 2 hours.","code":"oldfaithful #> # A tibble: 2,261 × 3 #>    time                duration waiting #>    <dttm>                 <dbl>   <dbl> #>  1 2015-01-02 14:53:00      271    5040 #>  2 2015-01-09 23:55:00      247    6060 #>  3 2015-02-07 00:49:00      203    5460 #>  4 2015-02-14 01:09:00      195    5221 #>  5 2015-02-21 01:12:00      210    5401 #>  6 2015-02-28 01:11:00      185    5520 #>  7 2015-03-07 00:50:00      160    5281 #>  8 2015-03-13 21:57:00      226    6000 #>  9 2015-03-13 23:37:00      190    5341 #> 10 2015-03-20 22:26:00      102    3961 #> # ℹ 2,251 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"kernel-density-estimates","dir":"","previous_headings":"","what":"Kernel density estimates","title":"Functions and Data Sets for ","text":"package provides kde_bandwidth() function estimating bandwidth kernel density estimate, dist_kde() constructing distribution, gg_density() plotting resulting density. figure shows kernel density estimate duration variable obtained using functions.  functions also work bivariate data. figure shows kernel density estimate duration waiting variables.","code":"of <- oldfaithful |>   filter(duration < 3600, waiting < 7200) dist_kde(of$duration) |>   gg_density(show_points = TRUE, jitter = TRUE) +   labs(x = \"Duration (seconds)\") of |>   select(duration, waiting) |>   dist_kde() |>   gg_density(show_points = TRUE, alpha = 0.15) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\")"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"statistical-tests","dir":"","previous_headings":"","what":"Statistical tests","title":"Functions and Data Sets for ","text":"old methods anomaly detection used statistical tests. recommended, still widely used, provided package comparison purposes. example, detect tiny 1-second duration, almost certainly recording error. explanation tests provided Chapter 4 book","code":"of |> filter(peirce_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700 of |> filter(chauvenet_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700 of |> filter(grubbs_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700 of |> filter(dixon_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"boxplots","dir":"","previous_headings":"","what":"Boxplots","title":"Functions and Data Sets for ","text":"Boxplots widely used anomaly detection. three variations boxplots applied duration variable.    latter two plots HDR boxplots, allow bimodality data seen. dark shaded region contains 50% observations, lighter shaded region contains 99% observations. plots use vertical jittering reduce overplotting, highlight potential outliers red using lookout algorithm (described Chapter 6 book). explanation plots provided Chapter 5 book. also possible produce bivariate boxplots. Several variations provided package. two types bagplot.   two types HDR boxplot   latter two plots show likely outliers red, using lookout algorithm.","code":"of |>   ggplot(aes(x = duration)) +   geom_boxplot() +   scale_y_discrete() +   labs(y = \"\", x = \"Duration (seconds)\") of |> gg_hdrboxplot(duration) +   labs(x = \"Duration (seconds)\") of |> gg_hdrboxplot(duration, scatterplot = TRUE) +   labs(x = \"Duration (seconds)\") of |>   gg_bagplot(duration, waiting) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\") of |>   gg_bagplot(duration, waiting, scatterplot = TRUE) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\") of |>   gg_hdrboxplot(duration, waiting) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\") of |>   gg_hdrboxplot(duration, waiting, scatterplot = TRUE) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\")"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"scoring-functions","dir":"","previous_headings":"","what":"Scoring functions","title":"Functions and Data Sets for ","text":"Several functions provided providing anomaly scores observations. surprisals() function uses either fitted statistical model, kernel density estimate, compute density scores. stray_scores() function uses stray algorithm compute anomaly scores. lof_scores() function uses local outlier factors compute anomaly scores. glosh_scores() function uses Global-Local Outlier Score Hierarchies algorithm compute anomaly scores. lookout() function uses lookout algorithm compute anomaly probabilities top 0.02% anomalous observations identified first four methods, along observations lookout probability less 0.05. addition surprisals() function, surprisal_prob() function computes probability obtaining surprisal values least extreme observed.","code":"of |>   mutate(     surprisal = surprisals(cbind(duration, waiting)),     strayscore = stray_scores(cbind(duration, waiting)),     lofscore = lof_scores(cbind(duration, waiting), k = 150),     gloshscore = glosh_scores(cbind(duration, waiting)),     lookout = lookout_prob(cbind(duration, waiting))   ) |>   filter(     surprisal > quantile(surprisal, prob = 0.998) |       strayscore > quantile(strayscore, prob = 0.998) |       lofscore > quantile(lofscore, prob = 0.998) |       gloshscore > quantile(gloshscore, prob = 0.998) |       lookout < 0.05   ) |>   arrange(lookout) #> # A tibble: 20 × 8 #>    time                duration waiting surprisal strayscore lofscore gloshscore #>    <dttm>                 <dbl>   <dbl>     <dbl>      <dbl>    <dbl>      <dbl> #>  1 2018-04-25 19:08:00        1    5700      17.5     0.380      3.78      1     #>  2 2020-06-01 21:04:00      120    6060      17.6     0.132      1.88      1     #>  3 2021-01-22 18:35:00      170    3600      16.9     0.0606     1.09      0.860 #>  4 2020-08-31 09:56:00      170    3840      16.8     0.0606     1.01      0.816 #>  5 2020-09-16 14:44:00      160    6120      15.9     0.0362     1.29      1     #>  6 2015-11-21 20:27:00      150    3420      16.7     0.0772     1.27      1     #>  7 2017-05-03 06:19:00       90    4740      16.3     0.0495     1.68      1     #>  8 2016-11-11 14:23:00      180    6480      15.8     0.0447     1.10      1     #>  9 2020-07-23 23:17:00      186    4320      16.0     0.0473     1.04      0.946 #> 10 2020-09-15 18:01:00      160    5880      15.6     0.0362     1.40      1     #> 11 2021-08-13 22:19:23      210    6971      15.8     0.0429     2.07      1     #> 12 2019-07-25 06:32:00      300    5280      15.9     0.0447     1.14      1     #> 13 2021-07-26 18:35:39      192    6618      15.7     0.0392     1.26      1     #> 14 2016-12-09 23:10:00      166    6000      15.3     0.0201     1.35      1     #> 15 2017-08-03 23:39:00      165    4440      15.8     0.0447     1.14      0.943 #> 16 2020-10-15 17:11:00      220    7080      15.7     0.0429     2.42      1     #> 17 2017-08-12 13:14:00      120    4920      15.3     0.0690     1.53      1     #> 18 2017-09-22 18:51:00      281    7140      15.5     0.0333     2.64      1     #> 19 2020-05-18 21:21:00      272    7080      14.9     0.0333     2.42      1     #> 20 2018-09-22 16:37:00      253    7140      14.8     0.0200     2.63      1     #> # ℹ 1 more variable: lookout <dbl> of |>   mutate(     surprisal = surprisals(cbind(duration, waiting)),     prob = surprisal_prob(cbind(duration, waiting))   ) |>   arrange(prob) #> # A tibble: 2,197 × 5 #>    time                duration waiting surprisal     prob #>    <dttm>                 <dbl>   <dbl>     <dbl>    <dbl> #>  1 2020-06-01 21:04:00      120    6060      17.6 0.000455 #>  2 2018-04-25 19:08:00        1    5700      17.5 0.000910 #>  3 2021-01-22 18:35:00      170    3600      16.9 0.00137  #>  4 2020-08-31 09:56:00      170    3840      16.8 0.00182  #>  5 2015-11-21 20:27:00      150    3420      16.7 0.00228  #>  6 2017-05-03 06:19:00       90    4740      16.3 0.00273  #>  7 2020-07-23 23:17:00      186    4320      16.0 0.00319  #>  8 2020-09-16 14:44:00      160    6120      15.9 0.00364  #>  9 2019-07-25 06:32:00      300    5280      15.9 0.00410  #> 10 2016-11-11 14:23:00      180    6480      15.8 0.00455  #> # ℹ 2,187 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"robust-multivariate-scaling","dir":"","previous_headings":"","what":"Robust multivariate scaling","title":"Functions and Data Sets for ","text":"anomaly detection methods require data scaled first, observations scale. However, many scaling methods robust anomalies. mvscale() function provides multivariate robust scaling method, optionally takes account relationships betwen variables, uses robust estimates center, scale covariance default. centers removed using medians, scale function IQR, covariance matrix estimated using robust OGK estimate. data scaled using Cholesky decomposition inverse covariance. scaled data returned. scaled variables rotated orthogonal, renamed z1, z2, etc. Non-rotated scaling possible setting cov = NULL.","code":"mvscale(of) #> Warning in mvscale(of): Ignoring non-numeric columns: time #> # A tibble: 2,197 × 3 #>    time                    z1     z2 #>    <dttm>               <dbl>  <dbl> #>  1 2015-01-02 14:53:00  2.06  -1.47  #>  2 2015-01-09 23:55:00  0.130  0.801 #>  3 2015-02-07 00:49:00 -1.78  -0.534 #>  4 2015-02-14 01:09:00 -2.04  -1.07  #>  5 2015-02-21 01:12:00 -1.38  -0.665 #>  6 2015-02-28 01:11:00 -2.76  -0.401 #>  7 2015-03-07 00:50:00 -3.92  -0.932 #>  8 2015-03-13 21:57:00 -0.932  0.668 #>  9 2015-03-13 23:37:00 -2.38  -0.799 #> 10 2015-03-20 22:26:00 -6.09  -3.87  #> # ℹ 2,187 more rows mvscale(of, cov = NULL) #> Warning in mvscale(of, cov = NULL): Ignoring non-numeric columns: time #> # A tibble: 2,197 × 3 #>    time                duration waiting #>    <dttm>                 <dbl>   <dbl> #>  1 2015-01-02 14:53:00    1.61   -1.48  #>  2 2015-01-09 23:55:00    0.363   0.809 #>  3 2015-02-07 00:49:00   -1.92   -0.540 #>  4 2015-02-14 01:09:00   -2.33   -1.08  #>  5 2015-02-21 01:12:00   -1.56   -0.672 #>  6 2015-02-28 01:11:00   -2.85   -0.405 #>  7 2015-03-07 00:50:00   -4.15   -0.942 #>  8 2015-03-13 21:57:00   -0.726   0.674 #>  9 2015-03-13 23:37:00   -2.59   -0.807 #> 10 2015-03-20 22:26:00   -7.16   -3.91  #> # ℹ 2,187 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Bagplot — gg_bagplot","title":"Bagplot — gg_bagplot","text":"Produces bivariate bagplot. bagplot analagous univariate boxplot, except two dimensions. Like boxplot, shows median, region containing 50% observations, region showing remaining observations outliers, outliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bagplot — gg_bagplot","text":"","code":"gg_bagplot(data, var1, var2, color = \"#00659e\", scatterplot = FALSE, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bagplot — gg_bagplot","text":"data data frame matrix containing data. var1 name first variable plot (bare expression). var2 name second variable plot (bare expression). color base color use median. colors generated mixture color white. scatterplot logical argument indicating regular bagplot required (FALSE), scatterplot colors required (TRUE). ... arguments passed compute.bagplot function.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bagplot — gg_bagplot","text":"ggplot object showing bagplot scatterplot data.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bagplot — gg_bagplot","text":"Rousseeuw, P. J., Ruts, ., & Tukey, J. W. (1999). bagplot: bivariate boxplot. American Statistician, 52(4), 382–387.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bagplot — gg_bagplot","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bagplot — gg_bagplot","text":"","code":"gg_bagplot(n01, v1, v2)  gg_bagplot(n01, v1, v2, scatterplot = TRUE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":null,"dir":"Reference","previous_headings":"","what":"Cricket batting data for international test players — cricket_batting","title":"Cricket batting data for international test players — cricket_batting","text":"dataset containing career batting statistics international test players (men women) 6 October 2021.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cricket batting data for international test players — cricket_batting","text":"","code":"cricket_batting"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cricket batting data for international test players — cricket_batting","text":"data frame 3754 rows 15 variables: Player Player name form \"initials surname\" Country Country played Start First year test playing career End Last year test playing career Matches Number matches played Innings Number innings batted NotOuts Number times Runs Total runs scored HighScore Highest score innings HighScoreNotOut highest score ? Average Batting average end career Hundreds Total number 100s scored Fifties Total number 50s scored Ducks Total number 0s scored Gender \"Men\" \"Women\"","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Cricket batting data for international test players — cricket_batting","text":"https://www.espncricinfo.com","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cricket batting data for international test players — cricket_batting","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cricket batting data for international test players — cricket_batting","text":"","code":"cricket_batting |>   filter(Innings > 20) |>   select(Player, Country, Matches, Runs, Average, Hundreds, Fifties, Ducks) |>   arrange(desc(Average)) #> # A tibble: 1,138 × 8 #>    Player        Country      Matches  Runs Average Hundreds Fifties Ducks #>    <chr>         <chr>          <int> <int>   <dbl>    <int>   <int> <int> #>  1 DG Bradman    Australia         52  6996    99.9       29      13     7 #>  2 AC Voges      Australia         20  1485    61.9        5       4     2 #>  3 SPD Smith     Australia         77  7540    61.8       27      31     5 #>  4 RG Pollock    South Africa      23  2256    61.0        7      11     1 #>  5 GA Headley    West Indies       22  2190    60.8       10       5     2 #>  6 M Labuschagne Australia         18  1885    60.8        5      10     1 #>  7 H Sutcliffe   England           54  4555    60.7       16      23     2 #>  8 E Bakewell    England           12  1078    59.9        4       7     0 #>  9 E Paynter     England           20  1540    59.2        4       7     3 #> 10 KF Barrington England           82  6806    58.7       20      35     5 #> # ℹ 1,128 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Create distributional object based on a specified density — dist_density","title":"Create distributional object based on a specified density — dist_density","text":"Creates distributional object using density specified pair vectors giving (x, f(x)). density assumed piecewise linear points provided, 0 outside range x.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create distributional object based on a specified density — dist_density","text":"","code":"dist_density(x, density)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create distributional object based on a specified density — dist_density","text":"x Numerical vector ordinates, list vectors. density Numerical vector density values, list vectors.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_density.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create distributional object based on a specified density — dist_density","text":"","code":"dist_density(seq(-4, 4, by = 0.01), dnorm(seq(-4, 4, by = 0.01))) #> <distribution[1]> #> [1] density[801]"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gev.html","id":null,"dir":"Reference","previous_headings":"","what":"The Generalized Extreme Value Distribution — dist_gev","title":"The Generalized Extreme Value Distribution — dist_gev","text":"GEV distribution function parameters \\(\\code{location} = \\), \\(\\code{scale} = b\\) \\(\\code{shape} = s\\) ","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Generalized Extreme Value Distribution — dist_gev","text":"","code":"dist_gev(location, scale, shape)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Generalized Extreme Value Distribution — dist_gev","text":"location location parameter \\(\\) GEV distribution. scale scale parameter \\(b\\) GEV distribution. shape shape parameter \\(s\\) GEV distribution.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gev.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Generalized Extreme Value Distribution — dist_gev","text":"$$F(x) = \\exp\\left[-\\{1+s(x-)/b\\}^{-1/s}\\right]$$ \\(1+s(x-)/b > 0\\), \\(b > 0\\). \\(s = 0\\) distribution defined continuity, giving $$F(x) = \\exp\\left[-\\exp\\left(-\\frac{x-}{b}\\right)\\right]$$ support distribution real line \\(s = 0\\), \\(x \\geq - b/s\\) \\(s \\neq 0\\), \\(x \\leq - b/s\\) \\(s < 0\\). parametric form GEV encompasses Gumbel, Frechet reverse Weibull distributions, obtained \\(s = 0\\), \\(s > 0\\) \\(s < 0\\) respectively. first introduced Jenkinson (1955).","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gev.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The Generalized Extreme Value Distribution — dist_gev","text":"Jenkinson, . F. (1955) frequency distribution annual maximum (minimum) meteorological elements. Quart. J. R. Met. Soc., 81, 158–171.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gev.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Generalized Extreme Value Distribution — dist_gev","text":"","code":"dist <- dist_gev(location = 0, scale = 1, shape = 0)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gpd.html","id":null,"dir":"Reference","previous_headings":"","what":"The Generalized Pareto Distribution — dist_gpd","title":"The Generalized Pareto Distribution — dist_gpd","text":"GPD distribution function parameters \\(\\code{location} = \\), \\(\\code{scale} = b\\) \\(\\code{shape} = s\\) ","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gpd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Generalized Pareto Distribution — dist_gpd","text":"","code":"dist_gpd(location, scale, shape)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gpd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Generalized Pareto Distribution — dist_gpd","text":"location location parameter \\(\\) GPD distribution. scale scale parameter \\(b\\) GPD distribution. shape shape parameter \\(s\\) GPD distribution.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gpd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The Generalized Pareto Distribution — dist_gpd","text":"$$F(x) = 1 - \\left(1+s(x-)/b\\right)^{-1/s}$$ \\(1+s(x-)/b > 0\\), \\(b > 0\\). \\(s = 0\\) distribution defined continuity, giving $$F(x) = 1 - \\exp\\left(-\\frac{x-}{b}\\right)$$ support distribution \\(x \\geq \\) \\(s \\geq 0\\), \\(\\leq x \\leq -b/s\\) \\(s < 0\\). Pickands–Balkema–De Haan theorem states large class distributions, tail (threshold) can approximated GPD.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_gpd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Generalized Pareto Distribution — dist_gpd","text":"","code":"dist <- dist_gpd(location = 0, scale = 1, shape = 0)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_kde.html","id":null,"dir":"Reference","previous_headings":"","what":"Create distributional object based on a kernel density estimate — dist_kde","title":"Create distributional object based on a kernel density estimate — dist_kde","text":"Creates distributional object using kernel density estimate Gaussian kernel obtained kde() function. bandwidth can specified; otherwise kde_bandwidth() function used. cdf, quantiles moments consistent kde. Generating random values kde equivalent smoothed bootstrap.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_kde.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create distributional object based on a kernel density estimate — dist_kde","text":"","code":"dist_kde(y, h = NULL, H = NULL, multiplier = 1, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_kde.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create distributional object based on a kernel density estimate — dist_kde","text":"y Numerical vector matrix data, list objects. list provided, objects dimension. e.g., vectors, matrices number columns. h Bandwidth univariate distribution. NULL, kde_bandwidth function used. H Bandwidth matrix multivariate distribution. NULL, kde_bandwidth function used. multiplier Multiplier bandwidth passed kde_bandwidth. Ignored h H specified. ... arguments passed kde.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/dist_kde.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create distributional object based on a kernel density estimate — dist_kde","text":"","code":"dist_kde(c(rnorm(200), rnorm(100, 5)), multiplier = 2) #> <distribution[1]> #> [1] kde[1d, h=2.2] dist_kde(cbind(rnorm(200), rnorm(200, 5))) #> <distribution[1]> #> [1] kde[2d, H={(0.21, 0.03)', (0.03, 0.17)'}]"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":null,"dir":"Reference","previous_headings":"","what":"Wine prices and points — fetch_wine_reviews","title":"Wine prices and points — fetch_wine_reviews","text":"data set containing data wines 44 countries, taken Wine Enthusiast Magazine week 15 June 2017. data downloaded returned.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wine prices and points — fetch_wine_reviews","text":"","code":"fetch_wine_reviews()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Wine prices and points — fetch_wine_reviews","text":"data frame 110,203 rows 8 columns: country Country origin state State province origin region Region origin winery Name vineyard made wine variety Variety grape points Points allocated WineEnthusiast reviewer scale 0-100 price Price bottle wine $US year Year wine extracted title","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Wine prices and points — fetch_wine_reviews","text":"https://kaggle.com","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wine prices and points — fetch_wine_reviews","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wine prices and points — fetch_wine_reviews","text":"","code":"if (FALSE) { # \\dontrun{ wine_reviews <- fetch_wine_reviews() wine_reviews |>   ggplot(aes(x = points, y = price)) +   geom_jitter(height = 0, width = 0.2, alpha = 0.1) +   scale_y_log10() } # }"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":null,"dir":"Reference","previous_headings":"","what":"French mortality rates by age and sex — fr_mortality","title":"French mortality rates by age and sex — fr_mortality","text":"data set containing French mortality rates years 1816 1999, age sex.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"French mortality rates by age and sex — fr_mortality","text":"","code":"fr_mortality"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"French mortality rates by age and sex — fr_mortality","text":"data frame 31,648 rows 4 columns.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"French mortality rates by age and sex — fr_mortality","text":"Human Mortality Database https://www.mortality.org","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"French mortality rates by age and sex — fr_mortality","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fr_mortality.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"French mortality rates by age and sex — fr_mortality","text":"","code":"fr_mortality #> # A tibble: 31,648 × 4 #>     Year   Age Sex    Mortality #>    <int> <int> <chr>      <dbl> #>  1  1816     0 Female   0.187   #>  2  1816     1 Female   0.0467  #>  3  1816     2 Female   0.0339  #>  4  1816     3 Female   0.0229  #>  5  1816     4 Female   0.0160  #>  6  1816     5 Female   0.0138  #>  7  1816     6 Female   0.0121  #>  8  1816     7 Female   0.0104  #>  9  1816     8 Female   0.00891 #> 10  1816     9 Female   0.00760 #> # ℹ 31,638 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"Produce ggplot densities distributional objects 1 2 dimensions","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"","code":"gg_density(   object,   prob = seq(9)/10,   fill = FALSE,   show_hdr = FALSE,   show_points = FALSE,   show_mode = FALSE,   show_anomalies = FALSE,   ngrid = 501,   color = \"#00659e\",   alpha = NULL,   jitter = FALSE,   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"object distribution object distributional package dist_kde() prob Probability HDR regions drawn. fill TRUE, density bivariate, bivariate contours shown filled regions rather lines. show_hdr TRUE, density univariate, HDR regions specified prob shown ribbon density. show_points TRUE, individual observations plotted. show_mode TRUE, mode distribution shown point. show_anomalies TRUE, observations surprisal probabilities less 0.01 shown red. ngrid Number points evaluate density function. color Color used mode HDR contours/regions one distribution. Otherwise ggplot color scale used. alpha Transparency points. Ignored show_points FALSE. Defaults min(1, 500/n), n number observations plotted. jitter TRUE show_points TRUE, small amount vertical jittering applied observations univariate distribution. ... Additional arguments currently ignored.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"ggplot object.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"function produces ggplot density distributional object. univariate densities, produces line plot density function, optional ribbon showing highest density regions (HDRs) /observations. bivariate densities, produces contour plot density function, observations optionally shown points. mode can also drawn point. bivariate densities, combination fill = TRUE, show_points = TRUE, show_mode = TRUE, prob = c(0.5, 0.99)equivalent showing HDR boxplot beneath density plot. univariate densities,  combination ofshow_hdr = TRUE, show_points = TRUE, show_mode = TRUE, prob = c(0.5, 0.99)` equivalent HDR boxplot.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce ggplot of densities from distributional objects in 1 or 2 dimensions — gg_density","text":"","code":"# Univariate density kde <- dist_kde(c(rnorm(500), rnorm(500, 4, .5))) gg_density(kde,   show_hdr = TRUE, prob = c(0.5, 0.95), color = \"#c14b14\",   show_mode = TRUE, show_points = TRUE, jitter = TRUE )  c(dist_normal(), kde) |>   gg_density(show_hdr = TRUE, prob = c(0.5, 0.95))  tibble(y1 = rnorm(5000), y2 = y1 + rnorm(5000)) |>   dist_kde() |>   gg_density(show_points = TRUE, alpha = 0.1, fill = TRUE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"Add ggplot layer densities distributional objects 1 dimension","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"","code":"gg_density_layer(object, ngrid = 501, scale = 1, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"object distribution object distributional package dist_kde() ngrid Number points evaluate density function. scale Scaling factor density function. ... Additional arguments passed geom_line.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"ggplot layer","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"function adds ggplot layer density distributional object. univariate densities, adds line plot density function. bivariate densities, adds contour plot density function.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/gg_density_layer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add ggplot layer of densities from distributional objects in 1 dimension — gg_density_layer","text":"","code":"library(distributional) dist_mixture(   dist_normal(-2, 1),   dist_normal(2, 1),   weights = c(1 / 3, 2 / 3) ) |>   gg_density() +   gg_density_layer(dist_normal(-2, 1), linetype = \"dashed\", scale = 1 / 3) +   gg_density_layer(dist_normal(2, 1), linetype = \"dashed\", scale = 2 / 3)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"GLOSH scores — glosh_scores","title":"GLOSH scores — glosh_scores","text":"Compute Global-Local Outlier Score Hierarchies. based hierarchical clustering minimum cluster size k. resulting outlier score measure anomalous observation . function uses dbscan::hdbscan calculation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GLOSH scores — glosh_scores","text":"","code":"glosh_scores(y, k = 10, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GLOSH scores — glosh_scores","text":"y Numerical matrix vector data k Minimum cluster size. Default: 5. ... Additional arguments passed dbscan::hdbscan","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GLOSH scores — glosh_scores","text":"Numerical vector containing GLOSH values","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"GLOSH scores — glosh_scores","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GLOSH scores — glosh_scores","text":"","code":"y <- c(rnorm(49), 5) glosh_scores(y) #>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #> [39] 1 1 1 1 1 1 1 1 1 1 1 1"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Grubbs' test (proposed 1950) identifies possible anomalies univariate data using z-scores assuming data come normal distribution. Dixon's test (also 1950) compares difference largest two values range data. Critical values Dixon's test computed using simulation interpolation using quadratic model logit(alpha) log(log(n)).","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"","code":"grubbs_anomalies(y, alpha = 0.05)  dixon_anomalies(y, alpha = 0.05, two_sided = TRUE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"y numerical vector observations alpha size test. two_sided TRUE, minimum maximums considered. Otherwise maximum used. (Take negative values consider minimum two_sided=FALSE.)","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"logical vector","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Grubbs' test based z-scores, point identified anomaly associated absolute z-score greater threshold value. vector logical values returned, TRUE indicates anomaly. version Grubbs' test looks outliers anywhere sample. Grubbs' original test came several variations looked one outlier, two outliers one tail, two outliers opposite tails. variations implemented grubbs.test function. Dixon's test considers maximum (possibly minimum) potential outliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Grubbs, F. E. (1950). Sample criteria testing outlying observations. Annals Mathematical Statistics, 21(1), 27–58. Dixon, W. J. (1950). Analysis extreme values. Annals Mathematical Statistics, 21(4), 488–506.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"","code":"x <- c(rnorm(1000), 5:10) tibble(x = x) |> filter(grubbs_anomalies(x)) #> # A tibble: 6 × 1 #>       x #>   <dbl> #> 1     5 #> 2     6 #> 3     7 #> 4     8 #> 5     9 #> 6    10 tibble(x = x) |> filter(dixon_anomalies(x)) #> # A tibble: 0 × 1 #> # ℹ 1 variable: x <dbl> y <- c(rnorm(1000), 5) tibble(y = y) |> filter(grubbs_anomalies(y)) #> # A tibble: 1 × 1 #>       y #>   <dbl> #> 1     5 tibble(y = y) |> filter(dixon_anomalies(y)) #> # A tibble: 1 × 1 #>       y #>   <dbl> #> 1     5"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify anomalies using the Hampel filter — hampel_anomalies","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"Hampel filter designed find anomalies time series data using mean absolute deviations vicinity observation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"","code":"hampel_anomalies(y, bandwidth, k = 3)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"y numeric vector containing time series bandwidth integer width window around observation k numeric number standard deviations declare outlier","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"logical vector identifying observations anomalies.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"First, moving median calculated using windows size 2 * bandwidth + 1. median absolute deviations moving median calculated moving windows. point declared anomaly MAD value k standard deviations. MAD converted standard deviation using MAD * 1.482602, holds normally distributed data. first bandwidth last bandwidth observations declared anomalies.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hampel_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify anomalies using the Hampel filter — hampel_anomalies","text":"","code":"set.seed(1) df <- tibble(   time = seq(41),   y = c(rnorm(20), 5, rnorm(20)) ) |>   mutate(hampel = hampel_anomalies(y, bandwidth = 3, k = 4)) df |> ggplot(aes(x = time, y = y)) +   geom_line() +   geom_point(data = df |> filter(hampel), col = \"red\")"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":null,"dir":"Reference","previous_headings":"","what":"HDR plot — gg_hdrboxplot","title":"HDR plot — gg_hdrboxplot","text":"Produces 1d 2d box plot HDR regions. darker regions contain observations higher probability, lighter regions contain points lower probability. Points outside largest HDR shown individual points. Points lookout probabilities less 0.05 optionally shown red.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HDR plot — gg_hdrboxplot","text":"","code":"gg_hdrboxplot(   data,   var1,   var2 = NULL,   prob = c(0.5, 0.99),   color = \"#00659e\",   scatterplot = FALSE,   show_lookout = FALSE,   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"HDR plot — gg_hdrboxplot","text":"data data frame matrix containing data. var1 name first variable plot (bare expression). var2 Optionally, name second variable plot (bare expression). prob numeric vector specifying coverage probabilities HDRs. color base color use mode. Colors HDRs generated whitening color. scatterplot logical argument indicating regular HDR plot required (FALSE), scatterplot colors required (TRUE). show_lookout logical argument indicating plot highlight observations \"lookout\" probabilities less 0.05. ... arguments passed kde.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"HDR plot — gg_hdrboxplot","text":"ggplot object showing HDR plot scatterplot data.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"HDR plot — gg_hdrboxplot","text":"original HDR boxplot proposed Hyndman (1996), R can produced arguments set defaults lookout.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"HDR plot — gg_hdrboxplot","text":"Hyndman, R J (1996) Computing Graphing Highest Density Regions, American Statistician, 50(2), 120–126. https://robjhyndman.com/publications/hdr/ Kandanaarachchi, S & Hyndman, R J (2022) \"Leave-one-kernel density estimates outlier detection\", J Computational & Graphical Statistics, 31(2), 586-599. https://robjhyndman.com/publications/lookout/","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"HDR plot — gg_hdrboxplot","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"HDR plot — gg_hdrboxplot","text":"","code":"df <- data.frame(x = c(rnorm(1000), rnorm(1000, 5, 1))) df$y <- df$x + rnorm(200, sd = 2) gg_hdrboxplot(df, x) #> Error in gg_density1(dist, show_hdr = TRUE, show_density = FALSE, ngrid = 501,     prob = prob, alpha = NULL, jitter = TRUE, color = color,     fill = TRUE, show_points = TRUE, show_mode = TRUE, show_lookout = show_lookout,     ...): argument \"show_anomalies\" is missing, with no default gg_hdrboxplot(df, x, y, scatterplot = TRUE) #> Error in gg_density2(dist, prob = prob, colors = NULL, color = color,     fill = !scatterplot, alpha = NULL, show_points = TRUE, show_mode = TRUE,     scatterplot = scatterplot, show_lookout = show_lookout): argument \"show_anomalies\" is missing, with no default oldfaithful |>   filter(duration < 7000, waiting < 7000) |>   gg_hdrboxplot(duration, waiting, scatterplot = TRUE) #> Error in gg_density2(dist, prob = prob, colors = NULL, color = color,     fill = !scatterplot, alpha = NULL, show_points = TRUE, show_mode = TRUE,     scatterplot = scatterplot, show_lookout = show_lookout): argument \"show_anomalies\" is missing, with no default cricket_batting |>   filter(Innings > 20) |>   gg_hdrboxplot(Average) #> Error in gg_density1(dist, show_hdr = TRUE, show_density = FALSE, ngrid = 501,     prob = prob, alpha = NULL, jitter = TRUE, color = color,     fill = TRUE, show_points = TRUE, show_mode = TRUE, show_lookout = show_lookout,     ...): argument \"show_anomalies\" is missing, with no default"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"Robust bandwidth estimation kernel density estimation","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"","code":"kde_bandwidth(data, multiplier = 1)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"data numeric matrix data frame. multiplier Bandwidths chosen using robust version normal reference rule multiplied constant. default 1.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"matrix bandwidths (scalar case univariate data).","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"","code":"# Univariate bandwidth calculation kde_bandwidth(oldfaithful$duration) #> [1] 4.526927 # Bivariate bandwidth calculation kde_bandwidth(oldfaithful[, 2:3]) #>           [,1]      [,2] #> [1,]  32.85912   182.179 #> [2,] 182.17895 16357.846"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Local outlier factors — lof_scores","title":"Local outlier factors — lof_scores","text":"Compute local outlier factors using k nearest neighbours. local outlier factor measure anomalous observation based density neighbouring points. function uses dbscan::lof calculation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local outlier factors — lof_scores","text":"","code":"lof_scores(y, k = 10, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local outlier factors — lof_scores","text":"y Numerical matrix vector data k Number neighbours include. Default: 5. ... Additional arguments passed dbscan::lof","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local outlier factors — lof_scores","text":"Numerical vector containing LOF values","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Local outlier factors — lof_scores","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local outlier factors — lof_scores","text":"","code":"y <- c(rnorm(49), 5) lof_scores(y) #>  [1] 0.9769239 1.2466344 1.2616415 1.1429039 0.9318119 1.0083383 1.3044620 #>  [8] 0.9942698 1.0857056 1.1271002 1.2591299 0.9611146 1.0118633 1.2923823 #> [15] 0.9726198 1.0959152 0.9985841 1.1900307 1.0336733 1.1774363 0.9683332 #> [22] 1.2923586 0.9569566 0.9520951 0.9799027 1.6317866 1.0143095 0.9996445 #> [29] 1.1213782 1.3819086 1.2705025 2.0847724 1.1285088 0.9817343 1.1271002 #> [36] 1.2639960 1.0219817 1.3423168 1.2474504 0.9318119 1.2506443 1.0019204 #> [43] 1.1633976 1.1271002 1.2509949 1.0278820 1.0512335 1.2833003 1.2680810 #> [50] 5.3831770"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Lookout probabilities — lookout_prob","title":"Lookout probabilities — lookout_prob","text":"lookout algorithm (Kandanaarachchi & Hyndman, 2022) computes leave-one-surprisal probabilities kernel density estimate using Generalized Pareto distribution. kernel density estimate uses bandwidth based topological data analysis quadratic kernel. similar identical using surprisal_prob loo = TRUE GPD = TRUE. low probability indicates likely anomaly.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lookout probabilities — lookout_prob","text":"","code":"lookout_prob(object, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lookout probabilities — lookout_prob","text":"object numerical data set. ... arguments passed lookout.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lookout probabilities — lookout_prob","text":"numerical vector containing lookout probabilities","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Lookout probabilities — lookout_prob","text":"Sevvandi Kandanaarachchi & Rob J Hyndman (2022) \"Leave-one-kernel density estimates outlier detection\", J Computational & Graphical Statistics, 31(2), 586-599. https://robjhyndman.com/publications/lookout/","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Lookout probabilities — lookout_prob","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout_prob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lookout probabilities — lookout_prob","text":"","code":"# Univariate data tibble(   y = c(5, rnorm(49)),   lookout = lookout_prob(y) ) #> # A tibble: 50 × 2 #>          y lookout #>      <dbl>   <dbl> #>  1  5        0     #>  2  1.10     1     #>  3 -1.14     1     #>  4  0.494    1     #>  5 -0.626    1     #>  6 -0.0465   1     #>  7 -0.594    1     #>  8  1.45     0.940 #>  9  0.984    1     #> 10  0.0242   1     #> # ℹ 40 more rows # Bivariate data tibble(   x = rnorm(50),   y = c(5, rnorm(49)),   lookout = lookout_prob(cbind(x,y)) ) #> # A tibble: 50 × 3 #>          x      y lookout #>      <dbl>  <dbl>   <dbl> #>  1 -0.171   5      0.0874 #>  2 -0.157   0.562  1      #>  3 -1.67    1.42   0.739  #>  4 -0.822   1.50   1      #>  5 -0.531  -1.08   1      #>  6  1.16    1.15   1      #>  7 -0.0894 -0.302  1      #>  8 -0.420   1.23   1      #>  9  0.957  -0.482  1      #> 10  2.28    1.05   0.430  #> # ℹ 40 more rows # Using a regression model of <- oldfaithful |> filter(duration < 7200, waiting < 7200) fit_of <- lm(waiting ~ duration, data = of) broom::augment(fit_of) |>   mutate(lookout = lookout_prob(.std.resid)) |>   arrange(lookout) #> # A tibble: 2,197 × 9 #>    waiting duration .fitted .resid     .hat .sigma .cooksd .std.resid lookout #>      <dbl>    <dbl>   <dbl>  <dbl>    <dbl>  <dbl>   <dbl>      <dbl>   <dbl> #>  1    5700        1   2837.  2863. 0.0138     424. 0.316         6.73  0      #>  2    6060      120   4274.  1786. 0.00348    427. 0.0304        4.17  0.0194 #>  3    6971      210   5360.  1611. 0.000541   427. 0.00383       3.76  0.0265 #>  4    7080      220   5481.  1599. 0.000473   427. 0.00329       3.73  0.0271 #>  5    3600      170   4877. -1277. 0.00133    428. 0.00593      -2.98  0.0285 #>  6    4500      241   5735. -1235. 0.000497   428. 0.00206      -2.88  0.0340 #>  7    6480      180   4998.  1482. 0.00106    428. 0.00633       3.46  0.0351 #>  8    6618      192   5143.  1475. 0.000795   428. 0.00471       3.44  0.0358 #>  9    6720      201   5252.  1468. 0.000647   428. 0.00380       3.43  0.0364 #> 10    3420      150   4636. -1216. 0.00204    428. 0.00823      -2.84  0.0368 #> # ℹ 2,187 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute robust multivariate scaled data — mvscale","title":"Compute robust multivariate scaled data — mvscale","text":"multivariate version base::scale(), takes account covariance matrix data, uses robust estimates center, scale covariance default. centers removed using medians, scale function IQR, covariance matrix estimated using robust OGK estimate. data scaled using Cholesky decomposition inverse covariance. scaled data returned. useful computing pairwise Mahalanobis distances.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute robust multivariate scaled data — mvscale","text":"","code":"mvscale(   object,   center = stats::median,   scale = robustbase::s_IQR,   cov = robustbase::covOGK,   warning = TRUE )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute robust multivariate scaled data — mvscale","text":"object vector, matrix, data frame containing numerical data. center function compute center numerical variable. Set NULL centering required. scale function scale numerical variable. cov = robustbase::covOGK, passed sigmamu argument. cov function compute covariance matrix. Set NULL rotation required. warning warning issued non-numeric columns ignored?","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute robust multivariate scaled data — mvscale","text":"vector, matrix data frame size class object, numerical variables replaced scaled versions.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute robust multivariate scaled data — mvscale","text":"Optionally, centering scaling can done variable separately, rotation data, setting cov = NULL. Also optionally, non-robust methods can used specifying center = mean, scale = stats::sd, cov = stats::cov. non-numeric columns retained warning.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute robust multivariate scaled data — mvscale","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute robust multivariate scaled data — mvscale","text":"","code":"# Univariate z-scores (no rotation) mvscale(oldfaithful, center = mean, scale = sd, cov = NULL, warning = FALSE) #> # A tibble: 2,261 × 3 #>    time                duration waiting #>    <dttm>                 <dbl>   <dbl> #>  1 2015-01-02 14:53:00   0.261  -0.258  #>  2 2015-01-09 23:55:00   0.104  -0.0337 #>  3 2015-02-07 00:49:00  -0.185  -0.166  #>  4 2015-02-14 01:09:00  -0.237  -0.218  #>  5 2015-02-21 01:12:00  -0.139  -0.179  #>  6 2015-02-28 01:11:00  -0.303  -0.153  #>  7 2015-03-07 00:50:00  -0.467  -0.205  #>  8 2015-03-13 21:57:00  -0.0340 -0.0469 #>  9 2015-03-13 23:37:00  -0.270  -0.192  #> 10 2015-03-20 22:26:00  -0.847  -0.496  #> # ℹ 2,251 more rows # Non-robust scaling with rotation mvscale(oldfaithful, center = mean, cov = stats::cov, warning = FALSE) #> # A tibble: 2,261 × 3 #>    time                     z1      z2 #>    <dttm>                <dbl>   <dbl> #>  1 2015-01-02 14:53:00  0.266  -0.258  #>  2 2015-01-09 23:55:00  0.104  -0.0337 #>  3 2015-02-07 00:49:00 -0.182  -0.166  #>  4 2015-02-14 01:09:00 -0.234  -0.218  #>  5 2015-02-21 01:12:00 -0.136  -0.179  #>  6 2015-02-28 01:11:00 -0.300  -0.153  #>  7 2015-03-07 00:50:00 -0.463  -0.205  #>  8 2015-03-13 21:57:00 -0.0332 -0.0469 #>  9 2015-03-13 23:37:00 -0.267  -0.192  #> 10 2015-03-20 22:26:00 -0.839  -0.496  #> # ℹ 2,251 more rows mvscale(oldfaithful, warning = FALSE) #> # A tibble: 2,261 × 3 #>    time                    z1     z2 #>    <dttm>               <dbl>  <dbl> #>  1 2015-01-02 14:53:00  1.91  -1.42  #>  2 2015-01-09 23:55:00  0.149  0.777 #>  3 2015-02-07 00:49:00 -1.71  -0.518 #>  4 2015-02-14 01:09:00 -1.97  -1.03  #>  5 2015-02-21 01:12:00 -1.33  -0.645 #>  6 2015-02-28 01:11:00 -2.63  -0.388 #>  7 2015-03-07 00:50:00 -3.74  -0.904 #>  8 2015-03-13 21:57:00 -0.862  0.647 #>  9 2015-03-13 23:37:00 -2.29  -0.775 #> 10 2015-03-20 22:26:00 -5.90  -3.75  #> # ℹ 2,251 more rows # Robust Mahalanobis distances oldfaithful |>   select(-time) |>   mvscale() |>   head(5) |>   dist() #>           1         2         3         4 #> 2 2.8170543                               #> 3 3.7249234 2.2623734                     #> 4 3.8979507 2.7884156 0.5800668           #> 5 3.3248738 2.0486310 0.4013823 0.7538288"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate standard normal data — n01","title":"Multivariate standard normal data — n01","text":"synthetic data set containing 1000 observations 10 variables generated independent standard normal distributions.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate standard normal data — n01","text":"","code":"n01"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Multivariate standard normal data — n01","text":"data frame 1000 rows 10 columns.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate standard normal data — n01","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate standard normal data — n01","text":"","code":"n01 #> # A tibble: 1,000 × 10 #>        v1      v2      v3      v4     v5     v6      v7     v8     v9     v10 #>     <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>  <dbl>  <dbl>   <dbl> #>  1 -0.626  1.13   -0.886   0.739  -1.13  -1.52  -0.619  -1.33   0.264 -1.22   #>  2  0.184  1.11   -1.92    0.387   0.765  0.629 -1.11    0.952 -0.829 -0.946  #>  3 -0.836 -0.871   1.62    1.30    0.571 -1.68  -2.17    0.860 -1.46   0.0914 #>  4  1.60   0.211   0.519  -0.804  -1.35   1.18  -0.0313  1.06   1.68   0.701  #>  5  0.330  0.0694 -0.0558 -1.60   -2.03   1.12  -0.260  -0.351 -1.54   0.673  #>  6 -0.820 -1.66    0.696   0.933   0.590 -1.24   0.534  -0.131 -0.191  1.27   #>  7  0.487  0.811   0.0535  1.81   -1.41  -1.23  -0.559   0.764  1.02  -1.45   #>  8  0.738 -1.91   -1.31   -0.0565  1.61   0.598  1.61   -0.494  0.547  1.42   #>  9  0.576 -1.25   -2.12    1.89    1.84   0.299  0.557   1.11   0.755 -1.59   #> 10 -0.305  0.998  -0.208   1.58    1.37  -0.110  0.186   1.46  -0.420  0.246  #> # ℹ 990 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":null,"dir":"Reference","previous_headings":"","what":"Old faithful eruption data — oldfaithful","title":"Old faithful eruption data — oldfaithful","text":"data set containing data recorded eruptions Old Faithful Geyser Yellowstone National Park, Wyoming, USA, 1 January 2015 1 October 2021. Recordings incomplete, especially winter months observers may present.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Old faithful eruption data — oldfaithful","text":"","code":"oldfaithful"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Old faithful eruption data — oldfaithful","text":"data frame 2261 rows 3 columns: time Time eruption started duration Duration eruption seconds waiting Time following eruption","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Old faithful eruption data — oldfaithful","text":"https://geysertimes.org","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Old faithful eruption data — oldfaithful","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Old faithful eruption data — oldfaithful","text":"","code":"oldfaithful |>   filter(duration < 7000, waiting < 7000) |>   ggplot(aes(x = duration, y = waiting)) +   geom_point()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"Peirce's criterion Chauvenet's criterion proposed 1800s way determining observations rejected univariate sample.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"","code":"peirce_anomalies(y)  chauvenet_anomalies(y)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"y numerical vector observations","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"logical vector","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"functions take univariate sample y return logical vector indicating observations considered anomalies according either Peirce's criterion Chauvenet's criterion.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"Peirce, B. (1852). Criterion rejection doubtful observations. Astronomical Journal, 2(21), 161–163. Chauvenet, W. (1863). 'Method least squares'. Appendix Manual Spherical Practical Astronomy, Vol.2, Lippincott, Philadelphia, pp.469-566.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"","code":"y <- rnorm(1000) tibble(y = y) |> filter(peirce_anomalies(y)) #> # A tibble: 0 × 1 #> # ℹ 1 variable: y <dbl> tibble(y = y) |> filter(chauvenet_anomalies(y)) #> # A tibble: 0 × 1 #> # ℹ 1 variable: y <dbl>"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. ggplot2 autoplot","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Stray anomalies — stray_anomalies","title":"Stray anomalies — stray_anomalies","text":"Test observations anomalies according stray algorithm.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stray anomalies — stray_anomalies","text":"","code":"stray_anomalies(y, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stray anomalies — stray_anomalies","text":"y vector, matrix, data frame consisting numerical variables. ... arguments passed find_HDoutliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stray anomalies — stray_anomalies","text":"Numerical vector containing logical values indicating observation identified anomaly using stray algorithm.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stray anomalies — stray_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stray anomalies — stray_anomalies","text":"","code":"# Univariate data y <- c(6, rnorm(49)) stray_anomalies(y) #>  [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [49] FALSE FALSE # Bivariate data y <- cbind(rnorm(50), c(5, rnorm(49))) stray_anomalies(y) #>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [49] FALSE FALSE"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Stray scores — stray_scores","title":"Stray scores — stray_scores","text":"Compute stray scores indicating anomalous observation .","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stray scores — stray_scores","text":"","code":"stray_scores(y, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stray scores — stray_scores","text":"y vector, matrix, data frame consisting numerical variables. ... arguments passed find_HDoutliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stray scores — stray_scores","text":"Numerical vector containing stray scores.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stray scores — stray_scores","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stray scores — stray_scores","text":"","code":"# Univariate data y <- c(6, rnorm(49)) scores <- stray_scores(y) threshold <- stray::find_threshold(scores, alpha = 0.01, outtail = \"max\", p = 0.5, tn = 50) which(scores > threshold) #> integer(0)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisal_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Surprisal probabilities — surprisal_prob","title":"Surprisal probabilities — surprisal_prob","text":"Compute probability surprisal least extreme observed. surprisal given \\(-\\log(f)\\) \\(f\\) density probability mass function distribution. surprisal values computed distribution provided. distribution provided, kernel density estimate used.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisal_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Surprisal probabilities — surprisal_prob","text":"","code":"surprisal_prob(   object,   distribution = NULL,   loo = FALSE,   GPD = FALSE,   threshold_probability = 0.1,   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisal_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Surprisal probabilities — surprisal_prob","text":"object model numerical data set. distribution probability distribution stored distributional object. Ignored object model. loo Logical value specifying leave-one-surprisals computed. GPD Logical value specifying Generalized Pareto distribution used estimate probabilities. threshold_probability Probability threshold computing GPD distribution surprisals. ... arguments passed surprisals.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisal_prob.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Surprisal probabilities — surprisal_prob","text":"surprisal probabilities may computed three different ways. Given distribution used compute surprisal values. option, surprisal probabilities equal 1 minus coverage probability largest HDR contains value. Surprisal probabilities smaller 1e-6 returned 1e-6. Using Generalized Pareto Distribution fitted extreme surprisal values (probability less threshold_probability). option used GPD = TRUE. surprisal values probability less threshold_probability, value threshold_probability returned. option, distribution used computing surprisal values determining probabilities. Due extreme value theory, resulting probabilities relatively insensitive distribution used computing surprisal values. Empirically proportion observations greater surprisal values. option used GPD = FALSE distribution explicitly provided. also insensitive distribution used computing surprisal values.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisal_prob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Surprisal probabilities — surprisal_prob","text":"","code":"# Univariate data tibble(   y = c(5, rnorm(49)),   p = surprisal_prob(y) ) #> Error in -density(distribution, at = object, log = TRUE): invalid argument to unary operator tibble(   y = n01$v1,   prob1 = surprisal_prob(y),   prob2 = surprisal_prob(y, GPD = TRUE),   prob3 = surprisal_prob(y, dist_normal()),   prob4 = surprisal_prob(y, dist_normal(), GPD = TRUE) ) |>   arrange(prob1) #> Error in -density(distribution, at = object, log = TRUE): invalid argument to unary operator # Bivariate data tibble(   x = rnorm(50),   y = c(5, rnorm(49)),   lookout = lookout_prob(cbind(x,y)) ) #> # A tibble: 50 × 3 #>         x      y lookout #>     <dbl>  <dbl>   <dbl> #>  1 -0.344  5       0     #>  2  0.429 -1.49    1     #>  3 -1.91  -0.478   0.975 #>  4  1.55  -0.937   1     #>  5  0.867  0.209   1     #>  6  1.49  -0.904   1     #>  7  1.21   1.18    1     #>  8  0.604 -1.32    1     #>  9  0.568 -1.78    1     #> 10  1.09   0.980   1     #> # ℹ 40 more rows # Using a regression model of <- oldfaithful |> filter(duration < 7200, waiting < 7200) fit_of <- lm(waiting ~ duration, data = of) of |>   mutate(p = surprisal_prob(fit_of)) |>   arrange(p) #> # A tibble: 2,197 × 4 #>    time                duration waiting        p #>    <dttm>                 <dbl>   <dbl>    <dbl> #>  1 2018-04-25 19:08:00        1    5700 0.000455 #>  2 2020-06-01 21:04:00      120    6060 0.000910 #>  3 2021-08-13 22:19:23      210    6971 0.00137  #>  4 2020-10-15 17:11:00      220    7080 0.00182  #>  5 2016-11-11 14:23:00      180    6480 0.00228  #>  6 2021-07-26 18:35:39      192    6618 0.00273  #>  7 2017-02-25 00:53:00      201    6720 0.00319  #>  8 2015-06-17 23:06:00      210    6780 0.00364  #>  9 2021-05-21 23:21:09      222    6891 0.00410  #> 10 2020-09-16 14:44:00      160    6120 0.00455  #> # ℹ 2,187 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Surprisals computed from a data set — surprisals.default","title":"Surprisals computed from a data set — surprisals.default","text":"Compute surprisals data set given probability distribution. surprisals defined minus log density observation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Surprisals computed from a data set — surprisals.default","text":"","code":"# Default S3 method surprisals(   object,   distribution = dist_kde(object, multiplier = 2, ...),   loo = FALSE,   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Surprisals computed from a data set — surprisals.default","text":"object numerical data  set, either vector, matrix data frame. distribution probability distribution stored distributional object. loo leave-one-surprisals computed? ... arguments passed dist_kde.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Surprisals computed from a data set — surprisals.default","text":"numerical vector containing surprisals.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.default.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Surprisals computed from a data set — surprisals.default","text":"distribution provided, kernel density estimate computed. leave-one-surprisals (LOO surprisals) obtained estimating kernel density estimate using observations.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.default.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Surprisals computed from a data set — surprisals.default","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Surprisals computed from a data set — surprisals.default","text":"","code":"# surprisals computed from bivariate data set oldfaithful |>   filter(duration < 7000, waiting < 7000) |>   mutate(     loo_fscores = surprisals(cbind(duration, waiting), loo = TRUE)   ) #> Error in mutate(filter(oldfaithful, duration < 7000, waiting < 7000),     loo_fscores = surprisals(cbind(duration, waiting), loo = TRUE)): ℹ In argument: `loo_fscores = surprisals(cbind(duration, waiting), loo = #>   TRUE)`. #> Caused by error in `-density(distribution, at = object, log = TRUE)`: #> ! invalid argument to unary operator"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.html","id":null,"dir":"Reference","previous_headings":"","what":"Surprisals — surprisals","title":"Surprisals — surprisals","text":"Compute surprisals model data set given probability distribution. surprisals defined minus log density observation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Surprisals — surprisals","text":"","code":"surprisals(object, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Surprisals — surprisals","text":"object model numerical data set ... arguments passed appropriate method.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Surprisals computed from a model — surprisals.lm","title":"Surprisals computed from a model — surprisals.lm","text":"Surprisals computed model","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Surprisals computed from a model — surprisals.lm","text":"","code":"# S3 method for class 'lm' surprisals(object, loo = FALSE, ...)  # S3 method for class 'gam' surprisals(object, loo = FALSE, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Surprisals computed from a model — surprisals.lm","text":"object model object returned lm, gam. loo leave-one-surprisals computed? ... arguments ignored.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/surprisals_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Surprisals computed from a model — surprisals.lm","text":"","code":"# surprisals computed from linear model of <- oldfaithful |>   filter(duration < 7200, waiting < 7200) lm_of <- lm(waiting ~ duration, data = of) of |>   mutate(     fscore = surprisals(lm_of),     loo_fscore = surprisals(lm_of, loo = TRUE),     #lookout_prob = lookout(surprisals = fscore, loo_scores = loo_fscore)   ) |>   ggplot(aes(x = duration, y = waiting,     color = loo_fscore > quantile(loo_fscore, 0.99))) +   geom_point()  # surprisals computed from GAM of <- oldfaithful |>   filter(duration > 1, duration < 7200, waiting < 7200) gam_of <- mgcv::gam(waiting ~ s(duration), data = of) of |>   mutate(fscore = surprisals(gam_of)) #> # A tibble: 2,196 × 4 #>    time                duration waiting fscore #>    <dttm>                 <dbl>   <dbl>  <dbl> #>  1 2015-01-02 14:53:00      271    5040  2.13  #>  2 2015-01-09 23:55:00      247    6060  1.27  #>  3 2015-02-07 00:49:00      203    5460  0.928 #>  4 2015-02-14 01:09:00      195    5221  0.984 #>  5 2015-02-21 01:12:00      210    5401  0.956 #>  6 2015-02-28 01:11:00      185    5520  0.921 #>  7 2015-03-07 00:50:00      160    5281  0.946 #>  8 2015-03-13 21:57:00      226    6000  1.34  #>  9 2015-03-13 23:37:00      190    5341  0.934 #> 10 2015-03-20 22:26:00      102    3961  0.920 #> # ℹ 2,186 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird-package.html","id":null,"dir":"Reference","previous_headings":"","what":"weird: Functions and Data Sets for ","title":"weird: Functions and Data Sets for ","text":"functions data sets required examples book Hyndman (2024) \"Weird: Anomaly Detection Using R\" https://OTexts.com/weird/. packages needed run examples also loaded.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"weird: Functions and Data Sets for ","text":"Maintainer: Rob Hyndman Rob.Hyndman@monash.edu (ORCID) [copyright holder] contributors: RStudio [copyright holder]","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":null,"dir":"Reference","previous_headings":"","what":"Conflicts between weird packages and other packages — weird_conflicts","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"function lists conflicts packages weird collection packages loaded.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"","code":"weird_conflicts()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"list object class weird_conflicts.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"conflicts deliberately ignored: intersect, union, setequal, setdiff dplyr; intersect, union, setdiff, .difftime lubridate. functions make base equivalents generic, negatively affect existing code.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"","code":"weird_conflicts() #> ── Conflicts ──────────────────────────────────────────────── weird_conflicts ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":null,"dir":"Reference","previous_headings":"","what":"List all packages loaded by weird — weird_packages","title":"List all packages loaded by weird — weird_packages","text":"List packages loaded weird","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List all packages loaded by weird — weird_packages","text":"","code":"weird_packages(include_self = FALSE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List all packages loaded by weird — weird_packages","text":"include_self Include weird list?","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List all packages loaded by weird — weird_packages","text":"character vector package names.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List all packages loaded by weird — weird_packages","text":"","code":"weird_packages() #>  [1] \"aplpack\"        \"broom\"          \"cli\"            \"crayon\"         #>  [5] \"dbscan\"         \"distributional\" \"dplyr\"          \"evd\"            #>  [9] \"ggplot2\"        \"grDevices\"      \"interpolation\"  \"ks\"             #> [13] \"lookout\"        \"mvtnorm\"        \"purrr\"          \"rlang\"          #> [17] \"robustbase\"     \"rstudioapi\"     \"stray\"          \"tibble\"         #> [21] \"vctrs\""},{"path":"https://pkg.robjhyndman.com/weird-package/news/index.html","id":"weird-development-version","dir":"Changelog","previous_headings":"","what":"weird (development version)","title":"weird (development version)","text":"Added fr_mortality data set Refactored package use distributional objects Removed as_kde() autoplot.kde() Added gg_density() gg_density_layer() Added surprisals() surprisal_prob() Renamed lookout() lookout_prob() Added hampel_anomalies() mvscale() resilient weird data","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/news/index.html","id":"weird-102","dir":"Changelog","previous_headings":"","what":"weird 1.0.2","title":"weird 1.0.2","text":"CRAN release: 2024-01-24 Removed wine_reviews dataset created fetch_wine_reviews() function. Bug fixes.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/news/index.html","id":"weird-100","dir":"Changelog","previous_headings":"","what":"weird 1.0.0","title":"weird 1.0.0","text":"CRAN release: 2024-01-12 Initial CRAN submission.","code":""}]
