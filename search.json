[{"path":"https://pkg.robjhyndman.com/weird-package/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rob Hyndman. Author, maintainer, copyright holder. RStudio. Copyright holder.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hyndman RJ (2024). weird: Functions Data Sets \"Weird: Anomaly Detection Using R\" Rob J Hyndman. R package version 1.0.2.9000, https://pkg.robjhyndman.com/weird-package/. Hyndman RJ (2024). Weird: Anomaly Detection Using R. OTexts, Melbourne, Australia. preparation, https://OTexts.com/weird/.","code":"@Manual{,   title = {{weird: Functions and Data Sets for \"That's Weird: Anomaly Detection Using R\" by Rob J Hyndman}},   author = {Rob J Hyndman},   year = {2024},   note = {R package version 1.0.2.9000},   url = {https://pkg.robjhyndman.com/weird-package/}, } @Book{,   title = {That's Weird: Anomaly Detection Using {R}},   author = {Rob J Hyndman},   year = {2024},   note = {In preparation},   publisher = {OTexts},   address = {Melbourne, Australia},   url = {https://OTexts.com/weird/}, }"},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Functions and Data Sets for ","text":"weird package contains functions data used book ’s Weird: Anomaly Detection Using R Rob J Hyndman. also loads several packages needed analysis described book.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Functions and Data Sets for ","text":"can install development version weird GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"robjhyndman/weird-package\")"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Functions and Data Sets for ","text":"library(weird) load following packages: dplyr, data manipulation. ggplot2, data visualisation. ks, fitting models producing forecasts. also get condensed summary conflicts packages loaded:","code":"library(weird) #> ── Attaching packages ────────────────────────────────────── weird 0.0.0.9000 ── #> ✔ dplyr   1.1.4      ✔ ks      1.14.1 #> ✔ ggplot2 3.4.4 #> ── Conflicts ──────────────────────────────────────────────── weird_conflicts ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag()"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"example-old-faithful-geyser-data","dir":"","previous_headings":"","what":"Example: Old Faithful Geyser data","title":"Functions and Data Sets for ","text":"oldfaithful data set contains eruption data Old Faithful Geyser Yellowstone National Park, Wyoming, USA, 1 January 2015 1 October 2021. data obtained geysertimes.org website. Recordings incomplete, especially winter months observers may present. also appear recording errors. data set contains 2261 observations 3 variables: time giving time eruption began, duration giving length eruption seconds, waiting giving time next eruption seconds. analysis , omit eruption duration greater 1 hour likely recording error. long waiting values probably due omitted eruptions, also omit eruptions waiting greater 2 hours.","code":"oldfaithful #> # A tibble: 2,261 × 3 #>    time                duration waiting #>    <dttm>                 <dbl>   <dbl> #>  1 2015-01-02 14:53:00      271    5040 #>  2 2015-01-09 23:55:00      247    6060 #>  3 2015-02-07 00:49:00      203    5460 #>  4 2015-02-14 01:09:00      195    5221 #>  5 2015-02-21 01:12:00      210    5401 #>  6 2015-02-28 01:11:00      185    5520 #>  7 2015-03-07 00:50:00      160    5281 #>  8 2015-03-13 21:57:00      226    6000 #>  9 2015-03-13 23:37:00      190    5341 #> 10 2015-03-20 22:26:00      102    3961 #> # ℹ 2,251 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"kernel-density-estimates","dir":"","previous_headings":"","what":"Kernel density estimates","title":"Functions and Data Sets for ","text":"package provides kde_bandwidth() function estimating bandwidth kernel density estimate, autoplot() method plotting resulting density. figure shows kernel density estimate duration variable obtained using functions. rug plot shows actual data values.  kde_bandwidth() function can also used estimate bandwidth bivariate kernel density estimate. figure shows kernel density estimate duration waiting variables using bandwidth selected kde_bandwidth() function. rug plot shows actual data values.","code":"of <- oldfaithful |>   filter(duration < 3600, waiting < 7200) of_density <- kde(of$duration, h=kde_bandwidth(of$duration)) of_density |>   autoplot() +   geom_rug(aes(x=duration), of) +   labs(x = \"Duration (seconds)\") of_density <- of |>   select(duration, waiting) |>    kde(H = kde_bandwidth(of[,c(\"duration\",\"waiting\")])) of_density |>   autoplot() +   geom_point(aes(duration, waiting), data = of, alpha=0.15) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\")"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"statistical-tests","dir":"","previous_headings":"","what":"Statistical tests","title":"Functions and Data Sets for ","text":"old methods anomaly detection used statistical tests. recommended, still widely used, provided package comparison purposes. example, detect tiny 1-second duration, almost certainly recording error. explanation tests provided Chapter 4 book","code":"of |> filter(peirce_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700 of |> filter(chauvenet_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700 of |> filter(grubbs_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700 of |> filter(dixon_anomalies(duration)) #> # A tibble: 1 × 3 #>   time                duration waiting #>   <dttm>                 <dbl>   <dbl> #> 1 2018-04-25 19:08:00        1    5700"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"boxplots","dir":"","previous_headings":"","what":"Boxplots","title":"Functions and Data Sets for ","text":"Boxplots widely used anomaly detection. three variations boxplots applied duration variable.    latter two plots HDR boxplots, allow bimodality data seen. dark shaded region contains 50% observations, lighter shaded region contains 99% observations. plots use vertical jittering reduce overplotting, highlight potential outliers red using lookout algorithm (described Chapter 6 book). explanation plots provided Chapter 5 book. also possible produce bivariate boxplots. Several variations provided package. two types bagplot.   two types HDR boxplot   latter two plots show likely outliers red, using lookout algorithm.","code":"of |>   ggplot(aes(x = duration)) +   geom_boxplot() +   scale_y_discrete() +   labs(y = \"\", x = \"Duration (seconds)\") of |> gg_hdrboxplot(duration) +   labs(x = \"Duration (seconds)\") of |> gg_hdrboxplot(duration, scatterplot = TRUE) +   labs(x = \"Duration (seconds)\") of |>   gg_bagplot(duration, waiting) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\") of |>   gg_bagplot(duration, waiting, scatterplot = TRUE) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\") of |>    gg_hdrboxplot(duration, waiting) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\") of |>    gg_hdrboxplot(duration, waiting, scatterplot = TRUE) +   labs(x = \"Duration (seconds)\", y = \"Waiting time (seconds)\")"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"scoring-functions","dir":"","previous_headings":"","what":"Scoring functions","title":"Functions and Data Sets for ","text":"Several functions provided providing anomaly scores observations. density_scores() function uses either fitted statistical model, kernel density estimate, compute density scores. stray_scores() function uses stray algorithm compute anomaly scores. lof_scores() function uses local outlier factors compute anomaly scores. glosh_scores() function uses Global-Local Outlier Score Hierarchies algorithm compute anomaly scores. lookout() function uses lookout algorithm compute anomaly probabilities top 0.02% anomalous observations identified first four methods, along observations lookout probability less 0.05.","code":"of |>   mutate(     denscore = density_scores(cbind(duration, waiting)),     strayscore = stray_scores(cbind(duration, waiting)),     lofscore = lof_scores(cbind(duration, waiting), k = 150),     gloshscore = glosh_scores(cbind(duration, waiting)),     lookout = lookout(cbind(duration, waiting))   ) |>    filter(     denscore > quantile(denscore, prob=0.998) |     strayscore > quantile(strayscore, prob=0.998) |     lofscore > quantile(lofscore, prob=0.998) |     gloshscore > quantile(gloshscore, prob=0.998) |     lookout < 0.05   ) |>    arrange(lookout) #> # A tibble: 11 × 8 #>    time                duration waiting denscore strayscore lofscore gloshscore #>    <dttm>                 <dbl>   <dbl>    <dbl>      <dbl>    <dbl>      <dbl> #>  1 2018-04-25 19:08:00        1    5700     17.5     0.380      3.78      1     #>  2 2020-06-01 21:04:00      120    6060     17.5     0.132      1.88      1     #>  3 2021-01-22 18:35:00      170    3600     16.8     0.0606     1.09      0.860 #>  4 2020-08-31 09:56:00      170    3840     16.7     0.0606     1.01      0.816 #>  5 2015-11-21 20:27:00      150    3420     16.7     0.0772     1.27      1     #>  6 2017-05-03 06:19:00       90    4740     16.4     0.0495     1.68      1     #>  7 2020-10-15 17:11:00      220    7080     15.7     0.0429     2.42      1     #>  8 2017-09-22 18:51:00      281    7140     15.5     0.0333     2.64      1     #>  9 2017-08-12 13:14:00      120    4920     15.2     0.0690     1.53      1     #> 10 2020-05-18 21:21:00      272    7080     14.9     0.0333     2.42      1     #> 11 2018-09-22 16:37:00      253    7140     14.7     0.0200     2.63      1     #> # ℹ 1 more variable: lookout <dbl>"},{"path":"https://pkg.robjhyndman.com/weird-package/index.html","id":"robust-multivariate-scaling","dir":"","previous_headings":"","what":"Robust multivariate scaling","title":"Functions and Data Sets for ","text":"anomaly detection methods require data scaled first, observations scale. However, many scaling methods robust anomalies. mvscale() function provides multivariate robust scaling method, optionally takes account relationships betwen variables, uses robust estimates center, scale covariance default. centers removed using medians, scale function IQR, covariance matrix estimated using robust OGK estimate. data scaled using Cholesky decomposition inverse covariance. scaled data returned. scaled variables rotated orthogonal, renamed z1, z2, etc. Non-rotated scaling possible setting cov = NULL.","code":"mvscale(of) #> Warning in mvscale(of): Ignoring non-numeric columns: time #> # A tibble: 2,197 × 3 #>    time                    z1     z2 #>    <dttm>               <dbl>  <dbl> #>  1 2015-01-02 14:53:00  2.06  -1.47  #>  2 2015-01-09 23:55:00  0.130  0.801 #>  3 2015-02-07 00:49:00 -1.78  -0.534 #>  4 2015-02-14 01:09:00 -2.04  -1.07  #>  5 2015-02-21 01:12:00 -1.38  -0.665 #>  6 2015-02-28 01:11:00 -2.76  -0.401 #>  7 2015-03-07 00:50:00 -3.92  -0.932 #>  8 2015-03-13 21:57:00 -0.932  0.668 #>  9 2015-03-13 23:37:00 -2.38  -0.799 #> 10 2015-03-20 22:26:00 -6.09  -3.87  #> # ℹ 2,187 more rows mvscale(of, cov = NULL) #> Warning in mvscale(of, cov = NULL): Ignoring non-numeric columns: time #> # A tibble: 2,197 × 3 #>    time                duration waiting #>    <dttm>                 <dbl>   <dbl> #>  1 2015-01-02 14:53:00    1.61   -1.48  #>  2 2015-01-09 23:55:00    0.363   0.809 #>  3 2015-02-07 00:49:00   -1.92   -0.540 #>  4 2015-02-14 01:09:00   -2.33   -1.08  #>  5 2015-02-21 01:12:00   -1.56   -0.672 #>  6 2015-02-28 01:11:00   -2.85   -0.405 #>  7 2015-03-07 00:50:00   -4.15   -0.942 #>  8 2015-03-13 21:57:00   -0.726   0.674 #>  9 2015-03-13 23:37:00   -2.59   -0.807 #> 10 2015-03-20 22:26:00   -7.16   -3.91  #> # ℹ 2,187 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/as_kde.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data frame or matrix object to kde class — as_kde","title":"Convert data frame or matrix object to kde class — as_kde","text":"density specified data frame matrix can converted kde object. useful plotting density using autoplot.kde. kde objects defined grid, density values interpolated based points data frame matrix.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/as_kde.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data frame or matrix object to kde class — as_kde","text":"","code":"as_kde(object, density_column, ngrid, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/as_kde.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data frame or matrix object to kde class — as_kde","text":"object Data frame matrix numerical columns, one column (specified density_column) contains density values, remaining columns define points density evaluated. density_column Name column containing density values, specified bare expression. missing, last column used. ngrid Number points use grid dimension. Default 10001 univariate densities 101 multivariate densities. ... Additional arguments ignored.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/as_kde.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data frame or matrix object to kde class — as_kde","text":"object class \"kde\"","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/as_kde.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert data frame or matrix object to kde class — as_kde","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/as_kde.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data frame or matrix object to kde class — as_kde","text":"","code":"tibble(y = seq(-4, 4, by = 0.01), density = dnorm(y)) |>   as_kde() #> Density of: [y] #> Computed on a grid of size 10001"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/autoplot.kde.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce ggplot of densities in 1 or 2 dimensions — autoplot.kde","title":"Produce ggplot of densities in 1 or 2 dimensions — autoplot.kde","text":"Produce ggplot densities 1 2 dimensions","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/autoplot.kde.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce ggplot of densities in 1 or 2 dimensions — autoplot.kde","text":"","code":"# S3 method for kde autoplot(   object,   prob = seq(9)/10,   fill = FALSE,   show_hdr = FALSE,   show_points = FALSE,   show_mode = FALSE,   show_lookout = FALSE,   color = \"#00659e\",   palette = hdr_palette,   alpha = ifelse(fill, 1, min(1, 1000/NROW(object$x))),   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/autoplot.kde.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce ggplot of densities in 1 or 2 dimensions — autoplot.kde","text":"object Probability density function estimated ks::kde(). prob Probability HDR contours drawn (bivariate plot ). fill TRUE, density bivariate, bivariate contours shown filled regions rather lines. show_hdr TRUE, density univariate, HDR regions specified prob shown ribbon density. show_points TRUE, individual points plotted. show_mode TRUE, mode distribution shown. show_lookout TRUE, observations lookout probabilities less 0.05 shown red. color Color used mode HDR contours. palette = hdr_palette, also used basis HDR regions. palette Color palette function use HDR filled regions (fill TRUE show_hdr TRUE). alpha Transparency points. fill FALSE, defaults min(1, 1000/n), n number observations. Otherwise, set 1. ... Additional arguments currently ignored.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/autoplot.kde.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce ggplot of densities in 1 or 2 dimensions — autoplot.kde","text":"ggplot object.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/autoplot.kde.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Produce ggplot of densities in 1 or 2 dimensions — autoplot.kde","text":"function produces ggplot density estimate produced ks::kde(). univariate densities, produces line plot density function, optional ribbon showing highest density regions (HDRs) /observations. bivariate densities, produces contour plot density function, observations optionally shown points. mode can also drawn point HDRs. bivariate densities, combination fill = TRUE, show_points = TRUE, show_mode = TRUE, prob = c(0.5, 0.99) equivalent HDR boxplot. univariate densities,  combination show_hdr = TRUE, show_points = TRUE, show_mode = TRUE, prob = c(0.5, 0.99) equivalent HDR boxplot.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/autoplot.kde.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce ggplot of densities in 1 or 2 dimensions — autoplot.kde","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/autoplot.kde.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce ggplot of densities in 1 or 2 dimensions — autoplot.kde","text":"","code":"# Univariate density c(rnorm(500), rnorm(500, 4, 1.5)) |>   kde() |>   autoplot(show_hdr = TRUE, prob= c(0.5, 0.95), color = \"#c14b14\")  ymat <- tibble(y1 = rnorm(5000), y2 = y1 + rnorm(5000)) ymat |>   kde(H = kde_bandwidth(ymat)) |>   autoplot(show_points = TRUE, alpha = 0.1, fill = TRUE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Bagplot — gg_bagplot","title":"Bagplot — gg_bagplot","text":"Produces bivariate bagplot. bagplot analagous univariate boxplot, except two dimensions. Like boxplot, shows median, region containing 50% observations, region showing remaining observations outliers, outliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bagplot — gg_bagplot","text":"","code":"gg_bagplot(   data,   var1,   var2,   col = c(hdr_palette(color = \"#00659e\", prob = c(0.5, 0.99)), \"#000000\"),   scatterplot = FALSE,   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bagplot — gg_bagplot","text":"data data frame matrix containing data. var1 name first variable plot (bare expression). var2 name second variable plot (bare expression). col colors use order: median, bag, loop outliers. scatterplot logical argument indicating regular bagplot required (FALSE), scatterplot colors required (TRUE). ... arguments passed compute.bagplot function.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bagplot — gg_bagplot","text":"ggplot object showing bagplot scatterplot data.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bagplot — gg_bagplot","text":"Rousseeuw, P. J., Ruts, ., & Tukey, J. W. (1999). bagplot: bivariate boxplot. American Statistician, 52(4), 382–387.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bagplot — gg_bagplot","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/bagplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bagplot — gg_bagplot","text":"","code":"gg_bagplot(n01, v1, v2)  gg_bagplot(n01, v1, v2, scatterplot = TRUE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":null,"dir":"Reference","previous_headings":"","what":"Cricket batting data for international test players — cricket_batting","title":"Cricket batting data for international test players — cricket_batting","text":"dataset containing career batting statistics international test players (men women) 6 October 2021.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cricket batting data for international test players — cricket_batting","text":"","code":"cricket_batting"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cricket batting data for international test players — cricket_batting","text":"data frame 3754 rows 15 variables: Player Player name form \"initials surname\" Country Country played Start First year test playing career End Last year test playing career Matches Number matches played Innings Number innings batted NotOuts Number times Runs Total runs scored HighScore Highest score innings HighScoreNotOut highest score ? Average Batting average end career Hundreds Total number 100s scored Fifties Total number 50s scored Ducks Total number 0s scored Gender \"Men\" \"Women\"","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Cricket batting data for international test players — cricket_batting","text":"https://www.espncricinfo.com","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cricket batting data for international test players — cricket_batting","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/cricket_batting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cricket batting data for international test players — cricket_batting","text":"","code":"cricket_batting |>   filter(Innings > 20) |>   select(Player, Country, Matches, Runs, Average, Hundreds, Fifties, Ducks) |>   arrange(desc(Average)) #> # A tibble: 1,138 × 8 #>    Player        Country      Matches  Runs Average Hundreds Fifties Ducks #>    <chr>         <chr>          <int> <int>   <dbl>    <int>   <int> <int> #>  1 DG Bradman    Australia         52  6996    99.9       29      13     7 #>  2 AC Voges      Australia         20  1485    61.9        5       4     2 #>  3 SPD Smith     Australia         77  7540    61.8       27      31     5 #>  4 RG Pollock    South Africa      23  2256    61.0        7      11     1 #>  5 GA Headley    West Indies       22  2190    60.8       10       5     2 #>  6 M Labuschagne Australia         18  1885    60.8        5      10     1 #>  7 H Sutcliffe   England           54  4555    60.7       16      23     2 #>  8 E Bakewell    England           12  1078    59.9        4       7     0 #>  9 E Paynter     England           20  1540    59.2        4       7     3 #> 10 KF Barrington England           82  6806    58.7       20      35     5 #> # ℹ 1,128 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/density_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Density scores — density_scores","title":"Density scores — density_scores","text":"Compute density scores leave-one-density scores model kernel density estimate data set. density scores defined minus log conditional density, kernel density estimate, observation. leave-one-density scores (LOO density scores) obtained estimating conditional density kernel density estimate using observations.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/density_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density scores — density_scores","text":"","code":"density_scores(object, loo = FALSE, ...)  # S3 method for default density_scores(   object,   loo = FALSE,   h = kde_bandwidth(object, method = \"double\"),   H = kde_bandwidth(object, method = \"double\"),   ... )  # S3 method for kde density_scores(object, loo = FALSE, ...)  # S3 method for lm density_scores(object, loo = FALSE, ...)  # S3 method for gam density_scores(object, loo = FALSE, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/density_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density scores — density_scores","text":"object model object numerical data set. loo leave-one-density scores computed? ... arguments ignored. h Bandwidth univariate kernel density estimate. Default kde_bandwidth. H Bandwidth multivariate kernel density estimate. Default kde_bandwidth.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/density_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density scores — density_scores","text":"numerical vector containing either density scores, LOO density scores.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/density_scores.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density scores — density_scores","text":"first argument numerical vector matrix, kernel density estimate computed, using Gaussian kernel, default bandwidth given robust normal reference rule. Otherwise model used compute conditional density function observation, density scores (possibly LOO density scores) obtained.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/density_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Density scores — density_scores","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/density_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density scores — density_scores","text":"","code":"# Density scores computed from bivariate data set of <- oldfaithful |>   filter(duration < 7000, waiting < 7000) |>   mutate(     fscores = density_scores(cbind(duration, waiting)),     loo_fscores = density_scores(cbind(duration, waiting), loo = TRUE),     lookout_prob = lookout(density_scores = fscores, loo_scores = loo_fscores)   ) of |>   ggplot(aes(x = duration, y = waiting, color = lookout_prob < 0.01)) +   geom_point()  # Density scores computed from bivariate KDE f_kde <- kde(of[, 2:3], H = kde_bandwidth(of[, 2:3])) of |>   mutate(     fscores = density_scores(f_kde),     loo_fscores = density_scores(f_kde, loo = TRUE)   ) #> # A tibble: 2,189 × 6 #>    time                duration waiting fscores loo_fscores lookout_prob #>    <dttm>                 <dbl>   <dbl>   <dbl>       <dbl>        <dbl> #>  1 2015-01-02 14:53:00      271    5040    14.6        14.9        0.795 #>  2 2015-01-09 23:55:00      247    6060    11.1        11.1        1     #>  3 2015-02-07 00:49:00      203    5460    13.0        13.0        1     #>  4 2015-02-14 01:09:00      195    5221    13.7        13.8        1     #>  5 2015-02-21 01:12:00      210    5401    12.5        12.5        1     #>  6 2015-02-28 01:11:00      185    5520    13.5        13.6        1     #>  7 2015-03-07 00:50:00      160    5281    15.7        17.0        0.164 #>  8 2015-03-13 21:57:00      226    6000    11.9        11.9        1     #>  9 2015-03-13 23:37:00      190    5341    13.6        13.7        1     #> 10 2015-03-20 22:26:00      102    3961    13.4        13.5        1     #> # ℹ 2,179 more rows # Density scores computed from linear model of <- oldfaithful |>   filter(duration < 7200, waiting < 7200) lm_of <- lm(waiting ~ duration, data = of) of |>   mutate(     fscore = density_scores(lm_of),     loo_fscore = density_scores(lm_of, loo = TRUE),     lookout_prob = lookout(density_scores = fscore, loo_scores = loo_fscore)   ) |>   ggplot(aes(x = duration, y = waiting, color = lookout_prob < 0.02)) +   geom_point()  # Density scores computed from GAM of <- oldfaithful |>   filter(duration > 1, duration < 7200, waiting < 7200) gam_of <- mgcv::gam(waiting ~ s(duration), data = of) of |>   mutate(     fscore = density_scores(gam_of),     lookout_prob = lookout(density_scores = fscore)   ) |>   filter(lookout_prob < 0.02) #> # A tibble: 4 × 5 #>   time                duration waiting fscore lookout_prob #>   <dttm>                 <dbl>   <dbl>  <dbl>        <dbl> #> 1 2016-07-05 10:34:00      240    7080  10.2       0.00375 #> 2 2017-05-31 17:01:00      246    7020   8.87      0.0123  #> 3 2017-09-08 23:23:00      246    7020   8.87      0.0123  #> 4 2018-09-29 22:10:00      241    4500   8.85      0.0125"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":null,"dir":"Reference","previous_headings":"","what":"Wine prices and points — fetch_wine_reviews","title":"Wine prices and points — fetch_wine_reviews","text":"data set containing data wines 44 countries, taken Wine Enthusiast Magazine week 15 June 2017. data downloaded returned.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wine prices and points — fetch_wine_reviews","text":"","code":"fetch_wine_reviews()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Wine prices and points — fetch_wine_reviews","text":"data frame 110,203 rows 8 columns: country Country origin state State province origin region Region origin winery Name vineyard made wine variety Variety grape points Points allocated WineEnthusiast reviewer scale 0-100 price Price bottle wine $US year Year wine extracted title","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Wine prices and points — fetch_wine_reviews","text":"https://kaggle.com","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wine prices and points — fetch_wine_reviews","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/fetch_wine_reviews.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wine prices and points — fetch_wine_reviews","text":"","code":"if (FALSE) { wine_reviews <- fetch_wine_reviews() wine_reviews |>  ggplot(aes(x = points, y = price)) +  geom_jitter(height = 0, width = 0.2, alpha = 0.1) +  scale_y_log10() }"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"GLOSH scores — glosh_scores","title":"GLOSH scores — glosh_scores","text":"Compute Global-Local Outlier Score Hierarchies. based hierarchical clustering minimum cluster size k. resulting outlier score measure anomalous observation . function uses dbscan::hdbscan calculation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GLOSH scores — glosh_scores","text":"","code":"glosh_scores(y, k = 10, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GLOSH scores — glosh_scores","text":"y Numerical matrix vector data k Minimum cluster size. Default: 5. ... Additional arguments passed dbscan::hdbscan","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GLOSH scores — glosh_scores","text":"Numerical vector containing GLOSH values","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"GLOSH scores — glosh_scores","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/glosh_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GLOSH scores — glosh_scores","text":"","code":"y <- c(rnorm(49), 5) glosh_scores(y) #>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #> [39] 1 1 1 1 1 1 1 1 1 1 1 1"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Grubbs' test (proposed 1950) identifies possible anomalies univariate data using z-scores assuming data come normal distribution. Dixon's test (also 1950) compares difference largest two values range data. Critical values Dixon's test computed using simulation interpolation using quadratic model logit(alpha) log(log(n)).","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"","code":"grubbs_anomalies(y, alpha = 0.05)  dixon_anomalies(y, alpha = 0.05, two_sided = TRUE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"y numerical vector observations alpha size test. two_sided TRUE, minimum maximums considered. Otherwise maximum used. (Take negative values consider minimum two_sided=FALSE.)","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"logical vector","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Grubbs' test based z-scores, point identified anomaly associated absolute z-score greater threshold value. vector logical values returned, TRUE indicates anomaly. version Grubbs' test looks outliers anywhere sample. Grubbs' original test came several variations looked one outlier, two outliers one tail, two outliers opposite tails. variations implemented grubbs.test function. Dixon's test considers maximum (possibly minimum) potential outliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Grubbs, F. E. (1950). Sample criteria testing outlying observations. Annals Mathematical Statistics, 21(1), 27–58. Dixon, W. J. (1950). Analysis extreme values. Annals Mathematical Statistics, 21(4), 488–506.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/grubbs_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statistical tests for anomalies using Grubbs' test and Dixon's test — grubbs_anomalies","text":"","code":"x <- c(rnorm(1000), 5:10) tibble(x = x) |> filter(grubbs_anomalies(x)) #> # A tibble: 6 × 1 #>       x #>   <dbl> #> 1     5 #> 2     6 #> 3     7 #> 4     8 #> 5     9 #> 6    10 tibble(x = x) |> filter(dixon_anomalies(x)) #> # A tibble: 0 × 1 #> # ℹ 1 variable: x <dbl> y <- c(rnorm(1000), 5) tibble(y = y) |> filter(grubbs_anomalies(y)) #> # A tibble: 1 × 1 #>       y #>   <dbl> #> 1     5 tibble(y = y) |> filter(dixon_anomalies(y)) #> # A tibble: 1 × 1 #>       y #>   <dbl> #> 1     5"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_palette.html","id":null,"dir":"Reference","previous_headings":"","what":"Color palette designed for plotting Highest Density Regions — hdr_palette","title":"Color palette designed for plotting Highest Density Regions — hdr_palette","text":"sequential color palette returned, first color color, rest colors mix color increasing amounts white. prob provided, mixing proportions determined prob (n ignored). Otherwise mixing proportions equally spaced 0 1.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_palette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Color palette designed for plotting Highest Density Regions — hdr_palette","text":"","code":"hdr_palette(n, color = \"#00659e\", prob = NULL)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_palette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Color palette designed for plotting Highest Density Regions — hdr_palette","text":"n Number colors palette. color First color vector. prob Vector probabilities 0 1.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_palette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Color palette designed for plotting Highest Density Regions — hdr_palette","text":"function returns vector colors length length(prob) + 1.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_palette.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Color palette designed for plotting Highest Density Regions — hdr_palette","text":"","code":"hdr_palette(prob = c(0.5, 0.99)) #> [1] \"#00659e\" \"#5598BE\" \"#A9CBDE\""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Table of Highest Density Regions — hdr_table","title":"Table of Highest Density Regions — hdr_table","text":"Compute highest density regions (HDR) kernel density estimate. HDRs returned tibble one row per interval columns: prob (giving probability coverage), density (value density boundary HDR), one dimensional density functions, tibble also columns lower (lower ends intervals), upper (upper ends interval), mode (point density maximized within interval).","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Table of Highest Density Regions — hdr_table","text":"","code":"hdr_table(   y = NULL,   density = NULL,   prob = c(0.5, 0.99),   h = kde_bandwidth(y, method = \"double\"),   H = kde_bandwidth(y, method = \"double\"),   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Table of Highest Density Regions — hdr_table","text":"y Numerical vector matrix data density Probability density function, either estimated ks::kde() data frame matrix numerical columns can passed as_kde(). prob Probability HDR h Bandwidth univariate kernel density estimate. Default kde_bandwidth. H Bandwidth multivariate kernel density estimate. Default kde_bandwidth. ... y supplied, arguments passed kde. Otherwise, additional arguments passed as_kde.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Table of Highest Density Regions — hdr_table","text":"tibble","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Table of Highest Density Regions — hdr_table","text":"Hyndman, R J. (1996) Computing Graphing Highest Density Regions, American Statistician, 50(2), 120–126.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Table of Highest Density Regions — hdr_table","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdr_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Table of Highest Density Regions — hdr_table","text":"","code":"# Univariate HDRs y <- c(rnorm(100), rnorm(100, 3, 1)) hdr_table(y = y) #> # A tibble: 2 × 5 #>    prob   lower upper  mode density #>   <dbl>   <dbl> <dbl> <dbl>   <dbl> #> 1  0.99 -1.95    4.93  1.49  0.0652 #> 2  0.5  -0.0291  3.03  1.49  0.136  hdr_table(density = ks::kde(y)) #> # A tibble: 3 × 5 #>    prob  lower upper  mode density #>   <dbl>  <dbl> <dbl> <dbl>   <dbl> #> 1  0.99 -1.95   4.82 0.262  0.0371 #> 2  0.5  -0.444  1.06 0.262  0.163  #> 3  0.5   2.52   3.73 3.22   0.163  x <- seq(-4, 4, by = 0.01) hdr_table(density = data.frame(y = x, density = dnorm(x)), prob = 0.95) #> # A tibble: 1 × 5 #>    prob lower upper  mode density #>   <dbl> <dbl> <dbl> <dbl>   <dbl> #> 1  0.95 -1.95  1.95     0  0.0598 # Bivariate HDRs y <- cbind(rnorm(100), rnorm(100)) hdr_table(y = y) #> # A tibble: 2 × 2 #>    prob density #>   <dbl>   <dbl> #> 1  0.99 0.00715 #> 2  0.5  0.0513  grid <- seq(-4, 4, by=0.1) density <- expand.grid(grid, grid) |>   mutate(density = dnorm(Var1) * dnorm(Var2)) hdr_table(density = density) #> # A tibble: 2 × 2 #>    prob density #>   <dbl>   <dbl> #> 1  0.99 0.00164 #> 2  0.5  0.0792"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":null,"dir":"Reference","previous_headings":"","what":"HDR plot — gg_hdrboxplot","title":"HDR plot — gg_hdrboxplot","text":"Produces 1d 2d box plot HDR regions. darker regions contain observations higher probability, lighter regions contain points lower probability. Points outside largest HDR shown individual points. Points lookout probabilities less 0.05 optionally shown red.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HDR plot — gg_hdrboxplot","text":"","code":"gg_hdrboxplot(   data,   var1,   var2 = NULL,   prob = c(0.5, 0.99),   color = \"#00659e\",   scatterplot = FALSE,   show_lookout = TRUE,   ... )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"HDR plot — gg_hdrboxplot","text":"data data frame matrix containing data. var1 name first variable plot (bare expression). var2 Optionally, name second variable plot (bare expression). prob numeric vector specifying coverage probabilities HDRs. color base color use mode. Colors HDRs generated whitening color. scatterplot logical argument indicating regular HDR plot required (FALSE), scatterplot colors required (TRUE). show_lookout logical argument indicating plot highlight observations \"lookout\" probabilities less 0.05. ... arguments passed kde.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"HDR plot — gg_hdrboxplot","text":"ggplot object showing HDR plot scatterplot data.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"HDR plot — gg_hdrboxplot","text":"original HDR boxplot proposed Hyndman (1996), R can produced arguments set defaults lookout.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"HDR plot — gg_hdrboxplot","text":"Hyndman, R J (1996) Computing Graphing Highest Density Regions, American Statistician, 50(2), 120–126. https://robjhyndman.com/publications/hdr/ Kandanaarachchi, S & Hyndman, R J (2022) \"Leave-one-kernel density estimates outlier detection\", J Computational & Graphical Statistics, 31(2), 586-599. https://robjhyndman.com/publications/lookout/","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"HDR plot — gg_hdrboxplot","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/hdrplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"HDR plot — gg_hdrboxplot","text":"","code":"df <- data.frame(x = c(rnorm(1000), rnorm(1000, 5, 1))) df$y <- df$x + rnorm(200, sd=2) gg_hdrboxplot(df, x)  gg_hdrboxplot(df, x, y, scatterplot = TRUE)  oldfaithful |>   filter(duration < 7000, waiting < 7000) |>   gg_hdrboxplot(duration, waiting, scatterplot = TRUE)  cricket_batting |>   filter(Innings > 20) |>   gg_hdrboxplot(Average)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":null,"dir":"Reference","previous_headings":"","what":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"Robust bandwidth estimation kernel density estimation","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"","code":"kde_bandwidth(   data,   method = c(\"robust_normal\", \"double\", \"lookout\"),   max.iter = 2 )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"data numeric matrix data frame. method Method use selecting bandwidth. robust_normal uses robust version normal reference rule. lookout uses topological data analysis approach part lookout algorithm. max.iter many times lookout method iterated. , outliers (probability < 0.05) removed bandwidth re-computed remaining observations.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"matrix bandwidths (scalar case univariate data).","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/kde_bandwidth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Robust bandwidth estimation for kernel density estimation — kde_bandwidth","text":"","code":"# Univariate bandwidth calculation kde_bandwidth(oldfaithful$duration) #> [1] 4.526927 # Bivariate bandwidth calculation kde_bandwidth(oldfaithful[,2:3]) #>           [,1]      [,2] #> [1,]  32.85912   182.179 #> [2,] 182.17895 16357.846"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Local outlier factors — lof_scores","title":"Local outlier factors — lof_scores","text":"Compute local outlier factors using k nearest neighbours. local outlier factor measure anomalous observation based density neighbouring points. function uses dbscan::lof calculation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local outlier factors — lof_scores","text":"","code":"lof_scores(y, k = 10, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local outlier factors — lof_scores","text":"y Numerical matrix vector data k Number neighbours include. Default: 5. ... Additional arguments passed dbscan::lof","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Local outlier factors — lof_scores","text":"Numerical vector containing LOF values","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Local outlier factors — lof_scores","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lof_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Local outlier factors — lof_scores","text":"","code":"y <- c(rnorm(49), 5) lof_scores(y) #>  [1] 1.0955266 1.3574208 0.9696143 1.1475907 3.5454478 1.1233799 1.0004632 #>  [8] 0.9643146 1.0277538 3.3031776 1.1992162 0.9866341 5.3386595 0.9715848 #> [15] 1.1045910 1.0021149 0.9524208 0.9809341 0.9731295 0.9665192 1.1985913 #> [22] 1.0082528 0.9727545 0.9818846 1.0261673 1.0450118 1.1541490 1.1614945 #> [29] 1.1836568 0.9938886 1.1619525 1.0490273 0.9886596 0.9806469 1.1797346 #> [36] 2.9499290 1.0032971 0.9789979 0.9821030 2.9462327 1.0340114 0.9996365 #> [43] 1.1322514 1.0005447 1.1764123 3.4474268 1.1951352 1.4531626 1.0213928 #> [50] 8.4933360"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout.html","id":null,"dir":"Reference","previous_headings":"","what":"Lookout probabilities — lookout","title":"Lookout probabilities — lookout","text":"Compute leave-one-log score probabilities using Generalized Pareto distribution. give probability observation anomaly.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lookout probabilities — lookout","text":"","code":"lookout(   object = NULL,   density_scores = NULL,   loo_scores = density_scores,   threshold_probability = 0.95 )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lookout probabilities — lookout","text":"object model object numerical data set. density_scores Numerical vector log scores loo_scores Optional numerical vector leave-one-log scores threshold_probability Probability threshold computing POT model log scores.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lookout probabilities — lookout","text":"numerical vector containing lookout probabilities","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Lookout probabilities — lookout","text":"function can work several object types. object NULL, object passed density_scores compute density scores (possibly LOO density scores). Otherwise, density scores taken density_scores argument, LOO density scores taken loo_scores argument. Generalized Pareto distribution fitted scores, obtain probability observation.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Lookout probabilities — lookout","text":"Sevvandi Kandanaarachchi & Rob J Hyndman (2022) \"Leave-one-kernel density estimates outlier detection\", J Computational & Graphical Statistics, 31(2), 586-599. https://robjhyndman.com/publications/lookout/","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Lookout probabilities — lookout","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/lookout.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lookout probabilities — lookout","text":"","code":"# Univariate data tibble(   y = c(5, rnorm(49)),   lookout = lookout(y) ) #> # A tibble: 50 × 2 #>          y lookout #>      <dbl>   <dbl> #>  1  5            0 #>  2 -1.03         1 #>  3  0.580        1 #>  4 -1.03         1 #>  5  0.731        1 #>  6  0.0221       1 #>  7  1.13         1 #>  8  0.0501       1 #>  9  1.08         1 #> 10  1.22         1 #> # ℹ 40 more rows # Bivariate data with score calculation done outside the function tibble(   x = rnorm(50),   y = c(5, rnorm(49)),   fscores = density_scores(y),   loo_fscores = density_scores(y, loo = TRUE),   lookout = lookout(density_scores = fscores, loo_scores = loo_fscores) ) #> # A tibble: 50 × 5 #>         x      y fscores loo_fscores lookout #>     <dbl>  <dbl>   <dbl>       <dbl>   <dbl> #>  1  0.385  5        4.79        6.62       0 #>  2  1.53   0.486    1.42        1.43       1 #>  3  1.10  -0.817    1.49        1.50       1 #>  4  1.56   2.31     2.48        2.55       1 #>  5 -0.140 -0.400    1.39        1.39       1 #>  6 -0.134 -1.00     1.55        1.57       1 #>  7  0.451  0.183    1.37        1.38       1 #>  8  1.64  -0.751    1.46        1.47       1 #>  9  0.792 -0.550    1.41        1.42       1 #> 10  0.221  0.941    1.56        1.58       1 #> # ℹ 40 more rows # Using a regression model of <- oldfaithful |> filter(duration < 7200, waiting < 7200) fit_of <- lm(waiting ~ duration, data = of) of |>   mutate(lookout_prob = lookout(fit_of)) |>   arrange(lookout_prob) #> # A tibble: 2,197 × 4 #>    time                duration waiting lookout_prob #>    <dttm>                 <dbl>   <dbl>        <dbl> #>  1 2018-04-25 19:08:00        1    5700     0.000990 #>  2 2020-06-01 21:04:00      120    6060     0.0192   #>  3 2021-08-13 22:19:23      210    6971     0.0356   #>  4 2020-10-15 17:11:00      220    7080     0.0371   #>  5 2016-11-11 14:23:00      180    6480     0.0572   #>  6 2021-07-26 18:35:39      192    6618     0.0587   #>  7 2017-02-25 00:53:00      201    6720     0.0603   #>  8 2015-06-17 23:06:00      210    6780     0.0728   #>  9 2021-05-21 23:21:09      222    6891     0.0833   #> 10 2020-09-16 14:44:00      160    6120     0.0908   #> # ℹ 2,187 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute robust multivariate scaled data — mvscale","title":"Compute robust multivariate scaled data — mvscale","text":"multivariate version base::scale(), takes account covariance matrix data, uses robust estimates center, scale covariance default. centers removed using medians, scale function IQR, covariance matrix estimated using robust OGK estimate. data scaled using Cholesky decomposition inverse covariance. scaled data returned. useful computing pairwise Mahalanobis distances.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute robust multivariate scaled data — mvscale","text":"","code":"mvscale(   object,   center = stats::median,   scale = robustbase::s_IQR,   cov = robustbase::covOGK,   warning = TRUE )"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute robust multivariate scaled data — mvscale","text":"object vector, matrix, data frame containing numerical data. center function compute center numerical variable. Set NULL centering required. scale function scale numerical variable. cov = robustbase::covOGK, passed sigmamu argument. cov function compute covariance matrix. Set NULL rotation required. warning warning issued non-numeric columns ignored?","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute robust multivariate scaled data — mvscale","text":"vector, matrix data frame size class object, numerical variables replaced scaled versions.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute robust multivariate scaled data — mvscale","text":"Optionally, centering scaling can done variable separately, rotation data, setting cov = NULL. Also optionally, non-robust methods can used specifying center = mean, scale = stats::sd, cov = stats::cov. non-numeric columns retained warning.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute robust multivariate scaled data — mvscale","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/mvscale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute robust multivariate scaled data — mvscale","text":"","code":"# Univariate z-scores (no rotation) mvscale(oldfaithful, center = mean, scale = sd, cov = NULL, warning = FALSE) #> # A tibble: 2,261 × 3 #>    time                duration waiting #>    <dttm>                 <dbl>   <dbl> #>  1 2015-01-02 14:53:00   0.261  -0.258  #>  2 2015-01-09 23:55:00   0.104  -0.0337 #>  3 2015-02-07 00:49:00  -0.185  -0.166  #>  4 2015-02-14 01:09:00  -0.237  -0.218  #>  5 2015-02-21 01:12:00  -0.139  -0.179  #>  6 2015-02-28 01:11:00  -0.303  -0.153  #>  7 2015-03-07 00:50:00  -0.467  -0.205  #>  8 2015-03-13 21:57:00  -0.0340 -0.0469 #>  9 2015-03-13 23:37:00  -0.270  -0.192  #> 10 2015-03-20 22:26:00  -0.847  -0.496  #> # ℹ 2,251 more rows # Non-robust scaling with rotation mvscale(oldfaithful, center = mean, cov = stats::cov, warning = FALSE) #> # A tibble: 2,261 × 3 #>    time                     z1      z2 #>    <dttm>                <dbl>   <dbl> #>  1 2015-01-02 14:53:00  0.266  -0.258  #>  2 2015-01-09 23:55:00  0.104  -0.0337 #>  3 2015-02-07 00:49:00 -0.182  -0.166  #>  4 2015-02-14 01:09:00 -0.234  -0.218  #>  5 2015-02-21 01:12:00 -0.136  -0.179  #>  6 2015-02-28 01:11:00 -0.300  -0.153  #>  7 2015-03-07 00:50:00 -0.463  -0.205  #>  8 2015-03-13 21:57:00 -0.0332 -0.0469 #>  9 2015-03-13 23:37:00 -0.267  -0.192  #> 10 2015-03-20 22:26:00 -0.839  -0.496  #> # ℹ 2,251 more rows mvscale(oldfaithful, warning = FALSE) #> # A tibble: 2,261 × 3 #>    time                    z1     z2 #>    <dttm>               <dbl>  <dbl> #>  1 2015-01-02 14:53:00  1.91  -1.42  #>  2 2015-01-09 23:55:00  0.149  0.777 #>  3 2015-02-07 00:49:00 -1.71  -0.518 #>  4 2015-02-14 01:09:00 -1.97  -1.03  #>  5 2015-02-21 01:12:00 -1.33  -0.645 #>  6 2015-02-28 01:11:00 -2.63  -0.388 #>  7 2015-03-07 00:50:00 -3.74  -0.904 #>  8 2015-03-13 21:57:00 -0.862  0.647 #>  9 2015-03-13 23:37:00 -2.29  -0.775 #> 10 2015-03-20 22:26:00 -5.90  -3.75  #> # ℹ 2,251 more rows # Robust Mahalanobis distances oldfaithful |>   select(-time) |>   mvscale() |>   head(5) |>   dist() #>           1         2         3         4 #> 2 2.8170543                               #> 3 3.7249234 2.2623734                     #> 4 3.8979507 2.7884156 0.5800668           #> 5 3.3248738 2.0486310 0.4013823 0.7538288"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate standard normal data — n01","title":"Multivariate standard normal data — n01","text":"synthetic data set containing 1000 observations 10 variables generated independent standard normal distributions.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate standard normal data — n01","text":"","code":"n01"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Multivariate standard normal data — n01","text":"data frame 1000 rows 10 columns.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multivariate standard normal data — n01","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/n01.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multivariate standard normal data — n01","text":"","code":"n01 #> # A tibble: 1,000 × 10 #>        v1      v2      v3      v4     v5     v6      v7     v8     v9     v10 #>     <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>  <dbl>  <dbl>   <dbl> #>  1 -0.626  1.13   -0.886   0.739  -1.13  -1.52  -0.619  -1.33   0.264 -1.22   #>  2  0.184  1.11   -1.92    0.387   0.765  0.629 -1.11    0.952 -0.829 -0.946  #>  3 -0.836 -0.871   1.62    1.30    0.571 -1.68  -2.17    0.860 -1.46   0.0914 #>  4  1.60   0.211   0.519  -0.804  -1.35   1.18  -0.0313  1.06   1.68   0.701  #>  5  0.330  0.0694 -0.0558 -1.60   -2.03   1.12  -0.260  -0.351 -1.54   0.673  #>  6 -0.820 -1.66    0.696   0.933   0.590 -1.24   0.534  -0.131 -0.191  1.27   #>  7  0.487  0.811   0.0535  1.81   -1.41  -1.23  -0.559   0.764  1.02  -1.45   #>  8  0.738 -1.91   -1.31   -0.0565  1.61   0.598  1.61   -0.494  0.547  1.42   #>  9  0.576 -1.25   -2.12    1.89    1.84   0.299  0.557   1.11   0.755 -1.59   #> 10 -0.305  0.998  -0.208   1.58    1.37  -0.110  0.186   1.46  -0.420  0.246  #> # ℹ 990 more rows"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":null,"dir":"Reference","previous_headings":"","what":"Old faithful eruption data — oldfaithful","title":"Old faithful eruption data — oldfaithful","text":"data set containing data recorded eruptions Old Faithful Geyser Yellowstone National Park, Wyoming, USA, 1 January 2015 1 October 2021. Recordings incomplete, especially winter months observers may present.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Old faithful eruption data — oldfaithful","text":"","code":"oldfaithful"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Old faithful eruption data — oldfaithful","text":"data frame 2261 rows 3 columns: time Time eruption started duration Duration eruption seconds waiting Time following eruption","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Old faithful eruption data — oldfaithful","text":"https://geysertimes.org","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Old faithful eruption data — oldfaithful","text":"Data frame","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/oldfaithful.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Old faithful eruption data — oldfaithful","text":"","code":"oldfaithful |>  filter(duration < 7000, waiting < 7000) |>  ggplot(aes(x = duration, y = waiting)) +  geom_point()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"Peirce's criterion Chauvenet's criterion proposed 1800s way determining observations rejected univariate sample.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"","code":"peirce_anomalies(y)  chauvenet_anomalies(y)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"y numerical vector observations","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"logical vector","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"functions take univariate sample y return logical vector indicating observations considered anomalies according either Peirce's criterion Chauvenet's criterion.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"Peirce, B. (1852). Criterion rejection doubtful observations. Astronomical Journal, 2(21), 161–163. Chauvenet, W. (1863). 'Method least squares'. Appendix Manual Spherical Practical Astronomy, Vol.2, Lippincott, Philadelphia, pp.469-566.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/peirce_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Anomalies according to Peirce's and Chauvenet's criteria — peirce_anomalies","text":"","code":"y <- rnorm(1000) tibble(y = y) |> filter(peirce_anomalies(y)) #> # A tibble: 1 × 1 #>       y #>   <dbl> #> 1 -3.74 tibble(y = y) |> filter(chauvenet_anomalies(y)) #> # A tibble: 1 × 1 #>       y #>   <dbl> #> 1 -3.74"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. ggplot2 autoplot","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":null,"dir":"Reference","previous_headings":"","what":"Stray anomalies — stray_anomalies","title":"Stray anomalies — stray_anomalies","text":"Test observations anomalies according stray algorithm.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stray anomalies — stray_anomalies","text":"","code":"stray_anomalies(y, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stray anomalies — stray_anomalies","text":"y vector, matrix, data frame consisting numerical variables. ... arguments passed find_HDoutliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stray anomalies — stray_anomalies","text":"Numerical vector containing logical values indicating observation identified anomaly using stray algorithm.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stray anomalies — stray_anomalies","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_anomalies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stray anomalies — stray_anomalies","text":"","code":"# Univariate data y <- c(6, rnorm(49)) stray_anomalies(y) #>  [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [49] FALSE FALSE # Bivariate data y <- cbind(rnorm(50), c(5, rnorm(49))) stray_anomalies(y) #>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [49] FALSE FALSE"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"Stray scores — stray_scores","title":"Stray scores — stray_scores","text":"Compute stray scores indicating anomalous observation .","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stray scores — stray_scores","text":"","code":"stray_scores(y, ...)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stray scores — stray_scores","text":"y vector, matrix, data frame consisting numerical variables. ... arguments passed find_HDoutliers.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stray scores — stray_scores","text":"Numerical vector containing stray scores.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stray scores — stray_scores","text":"Rob J Hyndman","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/stray_scores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stray scores — stray_scores","text":"","code":"# Univariate data y <- c(6, rnorm(49)) scores <- stray_scores(y) threshold <- stray::find_threshold(scores, alpha = 0.01, outtail = \"max\", p = 0.5, tn = 50) which(scores > threshold) #> integer(0)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird-package.html","id":null,"dir":"Reference","previous_headings":"","what":"weird: Functions and Data Sets for ","title":"weird: Functions and Data Sets for ","text":"functions data sets required examples book Hyndman (2024) \"Weird: Anomaly Detection Using R\" https://OTexts.com/weird/. packages needed run examples also loaded.","code":""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"weird: Functions and Data Sets for ","text":"Maintainer: Rob Hyndman Rob.Hyndman@monash.edu (ORCID) [copyright holder] contributors: RStudio [copyright holder]","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":null,"dir":"Reference","previous_headings":"","what":"Conflicts between weird packages and other packages — weird_conflicts","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"function lists conflicts packages weird collection packages loaded.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"","code":"weird_conflicts()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"list object class weird_conflicts.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"conflicts deliberately ignored: intersect, union, setequal, setdiff dplyr; intersect, union, setdiff, .difftime lubridate. functions make base equivalents generic, negatively affect existing code.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_conflicts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conflicts between weird packages and other packages — weird_conflicts","text":"","code":"weird_conflicts() #> ── Conflicts ──────────────────────────────────────────────── weird_conflicts ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag()"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":null,"dir":"Reference","previous_headings":"","what":"List all packages loaded by weird — weird_packages","title":"List all packages loaded by weird — weird_packages","text":"List packages loaded weird","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List all packages loaded by weird — weird_packages","text":"","code":"weird_packages(include_self = FALSE)"},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List all packages loaded by weird — weird_packages","text":"include_self Include weird list?","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List all packages loaded by weird — weird_packages","text":"character vector package names.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/reference/weird_packages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List all packages loaded by weird — weird_packages","text":"","code":"weird_packages() #>  [1] \"aplpack\"       \"broom\"         \"cli\"           \"crayon\"        #>  [5] \"dbscan\"        \"dplyr\"         \"evd\"           \"ggplot2\"       #>  [9] \"grDevices\"     \"interpolation\" \"ks\"            \"purrr\"         #> [13] \"rlang\"         \"robustbase\"    \"rstudioapi\"    \"stray\"         #> [17] \"tibble\""},{"path":[]},{"path":"https://pkg.robjhyndman.com/weird-package/news/index.html","id":"weird-102","dir":"Changelog","previous_headings":"","what":"weird 1.0.2","title":"weird 1.0.2","text":"CRAN release: 2024-01-24 Removed wine_reviews dataset created fetch_wine_reviews() function. Bug fixes.","code":""},{"path":"https://pkg.robjhyndman.com/weird-package/news/index.html","id":"weird-100","dir":"Changelog","previous_headings":"","what":"weird 1.0.0","title":"weird 1.0.0","text":"CRAN release: 2024-01-12 Initial CRAN submission.","code":""}]
